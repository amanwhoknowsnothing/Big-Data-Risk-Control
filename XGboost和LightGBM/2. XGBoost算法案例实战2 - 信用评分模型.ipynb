{"cells":[{"cell_type":"markdown","metadata":{"id":"1A660C864ABE4F61B85D42835E1136CF","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"# XGBoost算法案例实训 - 信用评分模型"},{"cell_type":"markdown","metadata":{"id":"B594A3A551E442CEA266FE32F19CBFAF","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"## 案例背景  \n\n为了降低不良贷款率，保障自身资金安全，提高风险控制水平，银行等金融机构会根据客户的信用历史资料构建信用评分模型给客户评分。根据客户的信用得分，可以估计客户按时还款的可能，并据此决定是否发放贷款及贷款的额度和利率。"},{"cell_type":"markdown","metadata":{"id":"6B816361D2914E3C8D5A8512858F5018","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"## 一、多元线性回归模型"},{"cell_type":"markdown","metadata":{"id":"AF3A69CD18D54212BC90B3A70C577BAE","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"### 1.读取数据"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:22:28.219201Z","start_time":"2020-11-21T02:22:28.112482Z"},"id":"6991955F29E84022B0E18C98410CF1D5","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"import pandas as pd\ndf = pd.read_excel('/home/mw/input/XG3004/信用评分卡模型.xlsx')\ndf.head()","outputs":[{"output_type":"execute_result","data":{"text/plain":"    月收入  年龄  性别  历史授信额度  历史违约次数  信用评分\n0  7783  29   0   32274       3    73\n1  7836  40   1    6681       4    72\n2  6398  25   0   26038       2    74\n3  6483  23   1   24584       4    65\n4  5167  23   1    6710       3    73","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>月收入</th>\n      <th>年龄</th>\n      <th>性别</th>\n      <th>历史授信额度</th>\n      <th>历史违约次数</th>\n      <th>信用评分</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7783</td>\n      <td>29</td>\n      <td>0</td>\n      <td>32274</td>\n      <td>3</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7836</td>\n      <td>40</td>\n      <td>1</td>\n      <td>6681</td>\n      <td>4</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6398</td>\n      <td>25</td>\n      <td>0</td>\n      <td>26038</td>\n      <td>2</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6483</td>\n      <td>23</td>\n      <td>1</td>\n      <td>24584</td>\n      <td>4</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5167</td>\n      <td>23</td>\n      <td>1</td>\n      <td>6710</td>\n      <td>3</td>\n      <td>73</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":1}],"execution_count":1},{"cell_type":"markdown","metadata":{"id":"1BE67AA4C4C346BCAA6AA649CDC534DC","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"### 2.提取特征变量和目标变量"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:22:29.141874Z","start_time":"2020-11-21T02:22:29.132934Z"},"id":"7D3D042D58514A8F8A0E881C8CE80B39","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 通过如下代码将特征变量和目标变量单独提取出来\nX = df.drop(columns='信用评分')\nY = df['信用评分']","outputs":[],"execution_count":2},{"cell_type":"markdown","metadata":{"id":"4D4090D00BAA432CACA31D201847DC5A","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"### 3.模型训练及搭建"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:22:33.476091Z","start_time":"2020-11-21T02:22:30.138622Z"},"id":"2C3D9A6A480B48A1AE9E25EF17A4AA01","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 从Scikit-Learn库中引入LinearRegression()模型进行模型训练\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X,Y)","outputs":[{"output_type":"execute_result","data":{"text/plain":"LinearRegression()"},"metadata":{},"execution_count":3}],"execution_count":3},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:22:33.501025Z","start_time":"2020-11-21T02:22:33.494044Z"},"id":"D1AFDB4DECF14ACABA874CC5DD3273CF","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"print('各系数为:' + str(model.coef_))\nprint('常数项系数k0为:' + str(model.intercept_))","outputs":[{"output_type":"stream","name":"stdout","text":"各系数为:[ 5.58658996e-04  1.62842002e-01  2.18430276e-01  6.69996665e-05\n -1.51063940e+00]\n常数项系数k0为:67.16686603853383\n"}],"execution_count":4},{"cell_type":"markdown","metadata":{"id":"1CDA33EFF2FA4C928136CC8607EAA539","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"### 4.模型评估"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:22:36.266474Z","start_time":"2020-11-21T02:22:33.518977Z"},"id":"7162D0E66EE8494DBB07A7E278DED5AC","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 利用模型评估的方法对此多元线性回归模型进行评估\nimport statsmodels.api as sm\nX2 = sm.add_constant(X)\nest = sm.OLS(Y, X2).fit()\nest.summary()","outputs":[{"output_type":"execute_result","data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   信用评分   R-squared:                       0.629\nModel:                            OLS   Adj. R-squared:                  0.628\nMethod:                 Least Squares   F-statistic:                     337.6\nDate:                Sat, 30 Sep 2023   Prob (F-statistic):          2.32e-211\nTime:                        19:04:14   Log-Likelihood:                -2969.8\nNo. Observations:                1000   AIC:                             5952.\nDf Residuals:                     994   BIC:                             5981.\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         67.1669      1.121     59.906      0.000      64.967      69.367\n月收入            0.0006   8.29e-05      6.735      0.000       0.000       0.001\n年龄             0.1628      0.022      7.420      0.000       0.120       0.206\n性别             0.2184      0.299      0.730      0.466      -0.369       0.806\n历史授信额度        6.7e-05   7.78e-06      8.609      0.000    5.17e-05    8.23e-05\n历史违约次数        -1.5106      0.140    -10.811      0.000      -1.785      -1.236\n==============================================================================\nOmnibus:                       13.180   Durbin-Watson:                   1.996\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               12.534\nSkew:                          -0.236   Prob(JB):                      0.00190\nKurtosis:                       2.721   Cond. No.                     4.27e+05\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 4.27e+05. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>          <td>信用评分</td>       <th>  R-squared:         </th> <td>   0.629</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.628</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   337.6</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Sat, 30 Sep 2023</td> <th>  Prob (F-statistic):</th> <td>2.32e-211</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>19:04:14</td>     <th>  Log-Likelihood:    </th> <td> -2969.8</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   5952.</td> \n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>   994</td>      <th>  BIC:               </th> <td>   5981.</td> \n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>  <td>   67.1669</td> <td>    1.121</td> <td>   59.906</td> <td> 0.000</td> <td>   64.967</td> <td>   69.367</td>\n</tr>\n<tr>\n  <th>月收入</th>    <td>    0.0006</td> <td> 8.29e-05</td> <td>    6.735</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n</tr>\n<tr>\n  <th>年龄</th>     <td>    0.1628</td> <td>    0.022</td> <td>    7.420</td> <td> 0.000</td> <td>    0.120</td> <td>    0.206</td>\n</tr>\n<tr>\n  <th>性别</th>     <td>    0.2184</td> <td>    0.299</td> <td>    0.730</td> <td> 0.466</td> <td>   -0.369</td> <td>    0.806</td>\n</tr>\n<tr>\n  <th>历史授信额度</th> <td>   6.7e-05</td> <td> 7.78e-06</td> <td>    8.609</td> <td> 0.000</td> <td> 5.17e-05</td> <td> 8.23e-05</td>\n</tr>\n<tr>\n  <th>历史违约次数</th> <td>   -1.5106</td> <td>    0.140</td> <td>  -10.811</td> <td> 0.000</td> <td>   -1.785</td> <td>   -1.236</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>13.180</td> <th>  Durbin-Watson:     </th> <td>   1.996</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  12.534</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.236</td> <th>  Prob(JB):          </th> <td> 0.00190</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.721</td> <th>  Cond. No.          </th> <td>4.27e+05</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.27e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."},"metadata":{},"execution_count":5}],"execution_count":5},{"cell_type":"markdown","metadata":{"id":"C27725A586CE4E42A1D78BE4AA7E4FD9","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"可以看到模型整体的R-squared为0.629，Adj. R-Squared为0.628，整体拟合效果一般，可能是因为数据量偏少的原因。同时我们再来观察P值，可以发现大部分特征变量的P值都较小（小于0.05），的确是和目标变量：信用评分显著相关，而性别这一特征变量的P值达到了0.466，即与目标变量没有显著相关性，这个也的确符合经验认知，所以在多元线性回归模型中，我们其实可以把性别这一特征变量舍去。"},{"cell_type":"markdown","metadata":{"id":"A88461079EA64A66B27DFCE66CC46C25","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"## 二、GBDT回归模型"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-11T09:26:45.484426Z","start_time":"2020-11-11T09:26:45.390927Z"},"id":"51F5E81F1C4E4E819C731099358E646C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 这里使用GBDT回归模型做回归分析，首先读取1000条信用卡客户的数据并划分特征变量和目标变量，这部分代码和上面线性回归的代码是一样的。\n\nimport pandas as pd\ndf = pd.read_excel('/home/mw/input/XG3004/信用评分卡模型.xlsx')\n\nX = df.drop(columns='信用评分')\ny = df['信用评分']","outputs":[],"execution_count":6},{"cell_type":"markdown","metadata":{"id":"38334A4CD821490AA11782B0FC5D6919","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"### 1.划分训练集和测试集"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-11T09:26:46.798900Z","start_time":"2020-11-11T09:26:46.790923Z"},"id":"1912E1018015426799B11D888AD8DE7A","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 划分训练集和测试集数据\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","outputs":[],"execution_count":7},{"cell_type":"markdown","metadata":{"id":"0074FE644EE24489B4ED17575AE41356","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"### 2.模型训练及搭建"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-11T09:26:47.881467Z","start_time":"2020-11-11T09:26:47.526390Z"},"id":"914704BE0B864AF7A625F130BAEA3107","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 从Scikit-Learn库中引入GBDT模型进行模型训练\nfrom sklearn.ensemble import GradientBoostingRegressor\nmodel = GradientBoostingRegressor()  # 使用默认参数\nmodel.fit(X_train, y_train)","outputs":[{"output_type":"execute_result","data":{"text/plain":"GradientBoostingRegressor()"},"metadata":{},"execution_count":8}],"execution_count":8},{"cell_type":"markdown","metadata":{"id":"A3CA33B6B6414D1AA550C2A0429F4849","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"### 3.模型预测及评估"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-11T09:26:50.133689Z","start_time":"2020-11-11T09:26:50.126678Z"},"id":"A1E8BB0246534C0AB6AE6AD5669F193B","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 模型搭建完毕后，通过如下代码预测测试集数据\ny_pred = model.predict(X_test)\nprint(y_pred[0:10])","outputs":[{"output_type":"stream","name":"stdout","text":"[70.77631652 71.40032104 73.73465155 84.52533945 71.09188294 84.9327599\n 73.72232388 83.44560704 82.61221486 84.86927209]\n"}],"execution_count":9},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-11T09:26:50.870097Z","start_time":"2020-11-11T09:26:50.857132Z"},"id":"3DA2F2BD6BF446118EB65A9192D23FDF","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 将预测值和实际值进行对比：\na = pd.DataFrame()  # 创建一个空DataFrame \na['预测值'] = list(y_pred)\na['实际值'] = list(y_test)\na.head()","outputs":[{"output_type":"execute_result","data":{"text/plain":"         预测值  实际值\n0  70.776317   79\n1  71.400321   80\n2  73.734652   62\n3  84.525339   89\n4  71.091883   80","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>预测值</th>\n      <th>实际值</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70.776317</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>71.400321</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>73.734652</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84.525339</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71.091883</td>\n      <td>80</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":10}],"execution_count":10},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-11T09:26:52.624845Z","start_time":"2020-11-11T09:26:52.618832Z"},"id":"F559ED79F1DC42A2949352F47E50BE1D","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 因为GradientBoostingRegressor()是一个回归模型，所以我们通过查看其R-squared值来评判模型的拟合效果：\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_test, model.predict(X_test))\nprint(r2)","outputs":[{"output_type":"stream","name":"stdout","text":"0.6774854432215086\n"}],"execution_count":11},{"cell_type":"markdown","metadata":{"id":"24C3571563284FB78660E65F2EB4727D","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"第1行代码从Scikit-Learn库中引入r2_score()函数；第2行代码将训练集的真实值和模型预测值传入r2_score()函数，得出R-squared评分为0.675，可以看到这个结果较线性回归模型获得的0.629是有所改善的。"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-11T09:26:53.462595Z","start_time":"2020-11-11T09:26:53.455614Z"},"id":"6F32EF552F534F4E96957C63D412DECD","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 我们还可以通过GradientBoostingRegressor()自带的score()函数来查看模型预测的效果：\nmodel.score(X_test, y_test)","outputs":[{"output_type":"execute_result","data":{"text/plain":"0.6774854432215086"},"metadata":{},"execution_count":12}],"execution_count":12},{"cell_type":"markdown","metadata":{"id":"AAC9B285042549C3AC5FD580E687EC40","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"## 三、XGBoost回归模型"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:36:46.958790Z","start_time":"2020-11-21T02:36:46.852520Z"},"id":"DE11C265F9014051A30A7A1A60BB3C82","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 1.读取数据\nimport pandas as pd\ndf = pd.read_excel('/home/mw/input/XG3004/信用评分卡模型.xlsx')\n# 2.提取特征变量和目标变量\nX = df.drop(columns='信用评分')\ny = df['信用评分']\n# 3.划分测试集和训练集\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","outputs":[],"execution_count":13},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:36:48.130533Z","start_time":"2020-11-21T02:36:48.055714Z"},"id":"899D5F327587435481CD3F2ED1556857","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 4.模型训练及搭建\nfrom xgboost import XGBRegressor\nmodel = XGBRegressor()  # 使用默认参数\nmodel.fit(X_train, y_train)","outputs":[{"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n             reg_lambda=1, ...)"},"metadata":{},"execution_count":14}],"execution_count":14},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:36:50.008022Z","start_time":"2020-11-21T02:36:50.000509Z"},"id":"5CC462DF360C4D81B1682416CA35A669","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 5.模型预测及评估\ny_pred = model.predict(X_test)\nprint(y_pred[0:10])","outputs":[{"output_type":"stream","name":"stdout","text":"[74.62306  69.01495  76.393486 83.88998  71.5683   86.257324 76.0784\n 81.38994  81.05504  83.24717 ]\n"}],"execution_count":15},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:36:51.164836Z","start_time":"2020-11-21T02:36:51.153865Z"},"id":"9E95E89FED2A4B37B7D5F301C59B1CD0","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 将预测值和实际值进行对比：\na = pd.DataFrame()  # 创建一个空DataFrame \na['预测值'] = list(y_pred)\na['实际值'] = list(y_test)\na.head()","outputs":[{"output_type":"execute_result","data":{"text/plain":"         预测值  实际值\n0  74.623062   79\n1  69.014954   80\n2  76.393486   62\n3  83.889977   89\n4  71.568298   80","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>预测值</th>\n      <th>实际值</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>74.623062</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>69.014954</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>76.393486</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>83.889977</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71.568298</td>\n      <td>80</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":16}],"execution_count":16},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:36:52.720157Z","start_time":"2020-11-21T02:36:52.712175Z"},"id":"914415616B5F4B19B8CD4F467F43FA96","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 因为XGBRegressor()是一个回归模型，所以通过查看R-squared来评判模型的拟合效果：\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_test, model.predict(X_test))\nprint(r2)","outputs":[{"output_type":"stream","name":"stdout","text":"0.5715437436791975\n"}],"execution_count":17},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:36:54.071187Z","start_time":"2020-11-21T02:36:54.063683Z"},"id":"19F0862CF6DD40A191EFB554B8020A7D","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 我们还可以通过XGBRegressor()自带的score()函数来查看模型预测的效果：\nmodel.score(X_test, y_test)","outputs":[{"output_type":"execute_result","data":{"text/plain":"0.5715437436791975"},"metadata":{},"execution_count":18}],"execution_count":18},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-11T09:29:22.018653Z","start_time":"2020-11-11T09:29:21.961806Z"},"id":"C0D43A03FE8C472497CD8DFD82CC6D49","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 6.查看特征重要性\nfeatures = X.columns  # 获取特征名称\nimportances = model.feature_importances_  # 获取特征重要性\n\n# 通过二维表格形式显示\nimportances_df = pd.DataFrame()\nimportances_df['特征名称'] = features\nimportances_df['特征重要性'] = importances\nimportances_df.sort_values('特征重要性', ascending=False)","outputs":[{"output_type":"execute_result","data":{"text/plain":"     特征名称     特征重要性\n0     月收入  0.324461\n4  历史违约次数  0.307467\n3  历史授信额度  0.202864\n1      年龄  0.098869\n2      性别  0.066339","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>特征名称</th>\n      <th>特征重要性</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>月收入</td>\n      <td>0.324461</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>历史违约次数</td>\n      <td>0.307467</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>历史授信额度</td>\n      <td>0.202864</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>年龄</td>\n      <td>0.098869</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>性别</td>\n      <td>0.066339</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":19}],"execution_count":19},{"cell_type":"markdown","metadata":{"id":"ECF5C692EF9E4CE0854657F70BDDC8A5","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"**补充知识点1：XGBoost回归模型的参数调优**"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:32:20.815490Z","start_time":"2020-11-21T02:32:20.810989Z"},"id":"CB76B7A0D1F94C9384F4B935254B39CD","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 对XGBoost回归模型进行参数调优，代码如下：\nfrom sklearn.model_selection import GridSearchCV  \nparameters = {'max_depth': [1, 3, 5], 'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.05, 0.1, 0.2]}  # 指定模型中参数的范围\nclf = XGBRegressor()  # 构建回归模型\ngrid_search = GridSearchCV(model, parameters, scoring='r2', cv=5) ","outputs":[],"execution_count":20},{"cell_type":"markdown","metadata":{"id":"0B89DEF4567D4B9B9D746EA47C43D36F","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"这里唯一需要注意的是最后一行代码中的scoring参数需要设置成'r2'，其表示的是R-squared值，因为是回归模型，所以参数调优时应该选择R-squared值来进行评判，而不是分类模型中常用的准确度'accuracy'或者ROC曲线对应的AUC值'roc_auc'。  \n通过如下代码获取最优参数："},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:32:30.955730Z","start_time":"2020-11-21T02:32:25.362409Z"},"id":"B80357D119C846778313E4057F2A02E0","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"grid_search.fit(X_train, y_train)  # 传入数据\ngrid_search.best_params_  # 输出参数的最优值","outputs":[{"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}"},"metadata":{},"execution_count":21}],"execution_count":21},{"cell_type":"markdown","metadata":{"id":"BAE3B53520FD4C1D8AB90180A93EA920","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"获得最优参数如下所示：  \n{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:33:15.929937Z","start_time":"2020-11-21T02:33:15.891042Z"},"id":"1481F372F964488ABEE6BCF9D4E9D24A","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 在模型中设置参数，代码如下：\nmodel = XGBRegressor(max_depth=3, n_estimators=50, learning_rate=0.1)\nmodel.fit(X_train, y_train)","outputs":[{"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints='()', n_estimators=50, n_jobs=0,\n             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n             reg_lambda=1, ...)"},"metadata":{},"execution_count":22}],"execution_count":22},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:33:17.274842Z","start_time":"2020-11-21T02:33:17.267903Z"},"id":"0F36ACC799464C36BBE59A226098A578","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 此时再通过r2_score()函数进行模型评估，代码如下（也可以用model.score(X_test, y_test)进行评分，效果一样）：\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_test, model.predict(X_test))\nprint(r2)","outputs":[{"output_type":"stream","name":"stdout","text":"0.6884486054771359\n"}],"execution_count":23},{"cell_type":"markdown","metadata":{"id":"60D33659915942C1B944BE49EF2BC572","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"此时获得的R-squared值如下所示：  \n0.688。  \n可以看到调参后的R-squared值优于未调参前的R-squared值0.678。"},{"cell_type":"markdown","metadata":{"id":"71942E7083E9486B8D36877FB395D2BA","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"### 对于XGBoost模型，有必要做很多数据预处理吗？"},{"cell_type":"markdown","metadata":{"id":"97BAE6E5ACF240D692B27908415BD464","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"在传统的机器模型中，我们往往需要做挺多的数据预处理，例如数据的归一化、缺失值及异常值的处理等，但是对于XGBoost模型而言，很多预处理都是不需要的，例如对于缺失值而言，XGBoost模型会自动处理，它会通过枚举所有缺失值在当前节点是进入左子树还是右子树来决定缺失值的处理方式。  \n\n此外由于XGBoost是基于决策树模型，因此区别于线性回归等模型，像一些特征变换（例如离散化、归一化或者叫作标准化、取log、共线性问题处理等）都不太需要，这也是树模型的一个优点。如果有的读者还不太放心，可以自己尝试下做一下特征变换，例如数据归一化，会发现最终的结果都是一样的。这里给大家简单示范一下，通过如下代码对数据进行Z-score标准化或者叫作归一化。"},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:36:34.849927Z","start_time":"2020-11-21T02:36:34.840950Z"},"id":"C1C4FC5486864A3D9EE37D8A6F287CCD","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"from sklearn.preprocessing import StandardScaler\nX_new = StandardScaler().fit_transform(X)\n\nX_new  # 打印标准化后的数据","outputs":[{"output_type":"execute_result","data":{"text/plain":"array([[-0.88269208, -1.04890243, -1.01409939, -0.60873764,  0.63591822],\n       [-0.86319167,  0.09630122,  0.98609664, -1.55243002,  1.27956013],\n       [-1.39227834, -1.46534013, -1.01409939, -0.83867808, -0.0077237 ],\n       ...,\n       [ 1.44337605,  0.61684833,  0.98609664,  1.01172301, -0.0077237 ],\n       [ 0.63723633, -0.21602705,  0.98609664, -0.32732239, -0.0077237 ],\n       [ 1.57656755,  0.61684833, -1.01409939,  1.30047599, -0.0077237 ]])"},"metadata":{},"execution_count":24}],"execution_count":24},{"cell_type":"markdown","metadata":{"id":"841F312FC8344CC4BE33BAB1CCF22AAA","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"利用标准化后的数据进行建模，看看是否有差别："},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-11-21T02:37:02.930820Z","start_time":"2020-11-21T02:37:02.850555Z"},"id":"C3123F2BEA994375B660375810E95522","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true},"source":"# 3.划分测试集和训练集\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=123)\n\n# 4.建模\n# 划分训练集和测试集完成后，就可以从Scikit-Learn库中引入XGBRegressor()模型进行模型训练了，代码如下：\nfrom xgboost import XGBRegressor\nmodel = XGBRegressor()  # 使用默认参数\nmodel.fit(X_train, y_train)\n\n# 因为XGBRegressor()是一个回归模型，所以通过查看R-squared来评判模型的拟合效果：\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_test, model.predict(X_test))\nprint(r2)","outputs":[{"output_type":"stream","name":"stdout","text":"0.5716150813375576\n"}],"execution_count":25},{"cell_type":"markdown","metadata":{"id":"140E654A779D4693BA18324B78C57DA4","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"65186d515177b26f2e3c2dd9","trusted":true,"runtime":{"status":"default","execution_status":null,"is_visible":false}},"source":"此时再对这个X_new通过train_test_split()函数划分测试集和训练集，并进行模型的训练，最后通过r2_score()获得模型评分，会发现结果和没有归一化的数据的结果几乎一样，为0.571。这里也验证了树模型不需要进行特征的归一化或者说标准化，此外树模型对于共线性也不敏感。  \n\n通过上面这个演示，也可以得出这么一个读者经常会问到的一个疑问：需不需要进行某种数据预处理？以后如果还有这样的疑问，那么不妨就做一下该数据预处理，如果发现最终结果没有区别，那就能够明白对于该模型不需要做相关数据预处理。  \n当然绝大部分模型都无法自动完成的一步就是特征提取。很多自然语言处理的问题或者图象的问题，没有现成的特征，需要人工去提取这些特征。  \n\n综上来说，XGBoost的确比线性模型要省去很多特征工程的步骤，但是特征工程依然是非常必要的，这一结论同样适用于下面即将讲到的LightGBM模型。"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":2}