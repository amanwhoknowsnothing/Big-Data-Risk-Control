{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-22T06:37:55.916444700Z",
     "start_time": "2023-12-22T06:37:02.874425800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# 加载数据\n",
    "data = np.load('data.npz')\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "edge_index = data['edge_index']\n",
    "train_mask_t= data['train_mask']\n",
    "test_mask = data['test_mask']\n",
    "edge_type = data['edge_type']\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(train_mask_t)\n",
    "train_mask = train_mask_t[:int(len(train_mask_t)/10*8)]\n",
    "valid_mask = train_mask_t[int(len(train_mask_t)/10*8):]\n",
    "# 将数据转换为PyTorch张量\n",
    "x_tensor = torch.tensor(x, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "edge_index_tensor = torch.tensor(edge_index.T, dtype=torch.long)\n",
    "edge_type_tensor = torch.tensor(edge_type, dtype=torch.float)\n",
    "\n",
    "# 创建掩码\n",
    "num_nodes = x.shape[0]\n",
    "train_mask_tensor = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask_tensor = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask_tensor=torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask_tensor[train_mask] = True\n",
    "test_mask_tensor[test_mask] = True\n",
    "val_mask_tensor[valid_mask]=True\n",
    "# 构造PyTorch Geometric的Data对象\n",
    "data = Data(x=x_tensor, edge_index=edge_index_tensor, edge_attr=edge_type_tensor,y=y_tensor)\n",
    "data.train_mask = train_mask_tensor\n",
    "data.test_mask = test_mask_tensor\n",
    "data.val_mask=val_mask_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T06:37:56.040155600Z",
     "start_time": "2023-12-22T06:37:55.921433300Z"
    }
   },
   "id": "76da579728278043"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATv2(\n",
      "  (conv1): GATv2Conv(17, 64, heads=1)\n",
      "  (conv2): GATv2Conv(64, 64, heads=1)\n",
      "  (conv3): GATv2Conv(64, 64, heads=1)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#这个GATv2还有点问题\n",
    "from torch import scatter_add\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, MessagePassing,SAGEConv,GCN2Conv,GATv2Conv\n",
    "from torch.nn import Linear, BatchNorm1d, Dropout\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GATv2, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GATv2Conv(data.num_node_features, hidden_channels) \n",
    "        self.conv2 =GATv2Conv(hidden_channels, hidden_channels)  \n",
    "        self.conv3 = GATv2Conv(hidden_channels, hidden_channels)  \n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "        self.dropout = Dropout(p=0.5) \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.conv1(x, edge_index,edge_weight) \n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index,edge_weight) \n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index,edge_weight)\n",
    "        x = x.relu() \n",
    "        x = self.dropout(x)  \n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data.to(device)\n",
    "model = GATv2(hidden_channels=64).to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T06:38:29.916419800Z",
     "start_time": "2023-12-22T06:38:27.857876600Z"
    }
   },
   "id": "163d2d76237a85c2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 28\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m200\u001B[39m):\n\u001B[1;32m---> 28\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: Loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# 使用模型进行预测\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[4], line 11\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      9\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 11\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(out[train_mask], data\u001B[38;5;241m.\u001B[39my[train_mask])\n\u001B[0;32m     14\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[3], line 25\u001B[0m, in \u001B[0;36mGATv2.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index, edge_weight):\n\u001B[1;32m---> 25\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m \n\u001B[0;32m     26\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mrelu()\n\u001B[0;32m     27\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x, edge_index,edge_weight) \n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:250\u001B[0m, in \u001B[0;36mGATv2Conv.forward\u001B[1;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001B[0m\n\u001B[0;32m    244\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    245\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe usage of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_attr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd_self_loops\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    246\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimultaneously is currently not yet supported for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    247\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_index\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in a \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSparseTensor\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m form\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001B[39;00m\n\u001B[1;32m--> 250\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_l\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_r\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    251\u001B[0m \u001B[43m                     \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    253\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m alpha \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:463\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    461\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    462\u001B[0m         msg_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 463\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmsg_kwargs)\n\u001B[0;32m    464\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    465\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:286\u001B[0m, in \u001B[0;36mGATv2Conv.message\u001B[1;34m(self, x_j, x_i, edge_attr, index, ptr, size_i)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m edge_attr\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    285\u001B[0m     edge_attr \u001B[38;5;241m=\u001B[39m edge_attr\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 286\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin_edge \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    287\u001B[0m edge_attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin_edge(edge_attr)\n\u001B[0;32m    288\u001B[0m edge_attr \u001B[38;5;241m=\u001B[39m edge_attr\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_channels)\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练函数\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x, data.edge_index,data.edge_attr)\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# 预测函数\n",
    "def predict(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x,data.edge_index,data.edge_attr)\n",
    "        predictions = torch.softmax(out, dim=1)\n",
    "        return predictions\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    print(f'Epoch {epoch}: Loss {loss}')\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = predict(model, data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T06:38:34.024355100Z",
     "start_time": "2023-12-22T06:38:31.701892600Z"
    }
   },
   "id": "5d4cf373b027f973"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): SAGEConv(17, 64, aggr=mean)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): SAGEConv(64, 128, aggr=mean)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): SAGEConv(128, 64, aggr=mean)\n",
      "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#SAGE是目前跑出来最好的，GAT其次，GCN最差\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = SAGEConv(data.num_node_features, hidden_channels)\n",
    "        self.bn1 = BatchNorm1d(hidden_channels)\n",
    "        self.conv2 =  SAGEConv(hidden_channels, 2*hidden_channels)\n",
    "        self.bn2 = BatchNorm1d(2*hidden_channels)\n",
    "        self.conv3 =  SAGEConv(2*hidden_channels, hidden_channels)\n",
    "        self.bn3 = BatchNorm1d(hidden_channels)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "        x = x.relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data.to(device)\n",
    "model = GCN(hidden_channels=64).to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T06:38:41.105077700Z",
     "start_time": "2023-12-22T06:38:41.070173400Z"
    }
   },
   "id": "58203f9d75d36c03"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 0.8718456625938416\n",
      "Epoch 1: Loss 0.5405719876289368\n",
      "Epoch 2: Loss 0.3474482297897339\n",
      "Epoch 3: Loss 0.23772968351840973\n",
      "Epoch 4: Loss 0.17143455147743225\n",
      "Epoch 5: Loss 0.13083529472351074\n",
      "Epoch 6: Loss 0.10724057257175446\n",
      "Epoch 7: Loss 0.09200483560562134\n",
      "Epoch 8: Loss 0.08204593509435654\n",
      "Epoch 9: Loss 0.07612668722867966\n",
      "Epoch 10: Loss 0.07224703580141068\n",
      "Epoch 11: Loss 0.06985025852918625\n",
      "Epoch 12: Loss 0.06862284988164902\n",
      "Epoch 13: Loss 0.0681423470377922\n",
      "Epoch 14: Loss 0.0669810026884079\n",
      "Epoch 15: Loss 0.06743597984313965\n",
      "Epoch 16: Loss 0.06774383038282394\n",
      "Epoch 17: Loss 0.06783169507980347\n",
      "Epoch 18: Loss 0.06728613376617432\n",
      "Epoch 19: Loss 0.06775026768445969\n",
      "Epoch 20: Loss 0.06792693585157394\n",
      "Epoch 21: Loss 0.06784023344516754\n",
      "Epoch 22: Loss 0.06837774813175201\n",
      "Epoch 23: Loss 0.06781025975942612\n",
      "Epoch 24: Loss 0.0679018571972847\n",
      "Epoch 25: Loss 0.06776556372642517\n",
      "Epoch 26: Loss 0.0678892508149147\n",
      "Epoch 27: Loss 0.0674399882555008\n",
      "Epoch 28: Loss 0.06699852645397186\n",
      "Epoch 29: Loss 0.06688030064105988\n",
      "Epoch 30: Loss 0.06709526479244232\n",
      "Epoch 31: Loss 0.06681365519762039\n",
      "Epoch 32: Loss 0.06626614928245544\n",
      "Epoch 33: Loss 0.0661817416548729\n",
      "Epoch 34: Loss 0.06604806333780289\n",
      "Epoch 35: Loss 0.06588484346866608\n",
      "Epoch 36: Loss 0.06568048894405365\n",
      "Epoch 37: Loss 0.06579656153917313\n",
      "Epoch 38: Loss 0.06549344956874847\n",
      "Epoch 39: Loss 0.06541317701339722\n",
      "Epoch 40: Loss 0.06530755758285522\n",
      "Epoch 41: Loss 0.06514275074005127\n",
      "Epoch 42: Loss 0.06484968215227127\n",
      "Epoch 43: Loss 0.06510600447654724\n",
      "Epoch 44: Loss 0.0648476779460907\n",
      "Epoch 45: Loss 0.06446155160665512\n",
      "Epoch 46: Loss 0.06476747244596481\n",
      "Epoch 47: Loss 0.06443443149328232\n",
      "Epoch 48: Loss 0.06461553275585175\n",
      "Epoch 49: Loss 0.06436585634946823\n",
      "Epoch 50: Loss 0.06411714851856232\n",
      "Epoch 51: Loss 0.06401278078556061\n",
      "Epoch 52: Loss 0.06420304626226425\n",
      "Epoch 53: Loss 0.06418395042419434\n",
      "Epoch 54: Loss 0.06392917037010193\n",
      "Epoch 55: Loss 0.06397178769111633\n",
      "Epoch 56: Loss 0.0639670193195343\n",
      "Epoch 57: Loss 0.06416568905115128\n",
      "Epoch 58: Loss 0.06391790509223938\n",
      "Epoch 59: Loss 0.06374645978212357\n",
      "Epoch 60: Loss 0.06382077932357788\n",
      "Epoch 61: Loss 0.0637170746922493\n",
      "Epoch 62: Loss 0.0634407326579094\n",
      "Epoch 63: Loss 0.06339677423238754\n",
      "Epoch 64: Loss 0.06370691955089569\n",
      "Epoch 65: Loss 0.06383447349071503\n",
      "Epoch 66: Loss 0.0630895122885704\n",
      "Epoch 67: Loss 0.0632534995675087\n",
      "Epoch 68: Loss 0.06328864395618439\n",
      "Epoch 69: Loss 0.06348053365945816\n",
      "Epoch 70: Loss 0.0636219009757042\n",
      "Epoch 71: Loss 0.06318672746419907\n",
      "Epoch 72: Loss 0.06334472447633743\n",
      "Epoch 73: Loss 0.06295228004455566\n",
      "Epoch 74: Loss 0.06288527697324753\n",
      "Epoch 75: Loss 0.06314059346914291\n",
      "Epoch 76: Loss 0.06329463422298431\n",
      "Epoch 77: Loss 0.06283749639987946\n",
      "Epoch 78: Loss 0.0626911148428917\n",
      "Epoch 79: Loss 0.06272763013839722\n",
      "Epoch 80: Loss 0.06272262334823608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练函数\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x, data.edge_index,data.edge_attr)\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# 预测函数\n",
    "def predict(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x,data.edge_index,data.edge_attr)\n",
    "        predictions = torch.softmax(out, dim=1)\n",
    "        return predictions\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    print(f'Epoch {epoch}: Loss {loss}')\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = predict(model, data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T06:38:53.152890600Z",
     "start_time": "2023-12-22T06:38:42.940090Z"
    }
   },
   "id": "60d51c59d5992623"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 构造测试集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "387cd34435347fb8"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "#用valdata本地测一下分数\n",
    "from sklearn.metrics import auc,roc_auc_score,roc_curve\n",
    "correct=0\n",
    "pred_test=predictions.cpu().numpy()[valid_mask]\n",
    "auc_score=roc_auc_score(y[valid_mask],pred_test[:,1])\n",
    "auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T06:38:35.931335800Z",
     "start_time": "2023-12-20T06:38:35.438775300Z"
    }
   },
   "id": "61dd6a13cb22c89f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 0.9720125794410706\n",
      "Epoch 1: Loss 0.6166316270828247\n",
      "Epoch 2: Loss 0.6127698421478271\n",
      "Epoch 3: Loss 0.6083108186721802\n",
      "Epoch 4: Loss 0.6023171544075012\n",
      "Epoch 5: Loss 0.5961865782737732\n",
      "Epoch 6: Loss 0.5786877870559692\n",
      "Epoch 7: Loss 0.5693234801292419\n",
      "Epoch 8: Loss 0.5544764995574951\n",
      "Epoch 9: Loss 0.5301185250282288\n",
      "Epoch 10: Loss 0.5032992959022522\n",
      "Epoch 11: Loss 0.4874825179576874\n",
      "Epoch 12: Loss 0.4701153039932251\n",
      "Epoch 13: Loss 0.4462882876396179\n",
      "Epoch 14: Loss 0.42865708470344543\n",
      "Epoch 15: Loss 0.4142681956291199\n",
      "Epoch 16: Loss 0.3918411135673523\n",
      "Epoch 17: Loss 0.37842851877212524\n",
      "Epoch 18: Loss 0.3660755753517151\n",
      "Epoch 19: Loss 0.3521394729614258\n",
      "Epoch 20: Loss 0.3356037735939026\n",
      "Epoch 21: Loss 0.32726117968559265\n",
      "Epoch 22: Loss 0.3153165280818939\n",
      "Epoch 23: Loss 0.3064103424549103\n",
      "Epoch 24: Loss 0.2979830801486969\n",
      "Epoch 25: Loss 0.2894017696380615\n",
      "Epoch 26: Loss 0.2815624475479126\n",
      "Epoch 27: Loss 0.27388995885849\n",
      "Epoch 28: Loss 0.2666645646095276\n",
      "Epoch 29: Loss 0.2594658434391022\n",
      "Epoch 30: Loss 0.2541864216327667\n",
      "Epoch 31: Loss 0.24796657264232635\n",
      "Epoch 32: Loss 0.24214209616184235\n",
      "Epoch 33: Loss 0.23703540861606598\n",
      "Epoch 34: Loss 0.232664093375206\n",
      "Epoch 35: Loss 0.22700758278369904\n",
      "Epoch 36: Loss 0.22172093391418457\n",
      "Epoch 37: Loss 0.21650350093841553\n",
      "Epoch 38: Loss 0.21147529780864716\n",
      "Epoch 39: Loss 0.20673158764839172\n",
      "Epoch 40: Loss 0.20289753377437592\n",
      "Epoch 41: Loss 0.19886139035224915\n",
      "Epoch 42: Loss 0.19465205073356628\n",
      "Epoch 43: Loss 0.19092458486557007\n",
      "Epoch 44: Loss 0.18725982308387756\n",
      "Epoch 45: Loss 0.18340253829956055\n",
      "Epoch 46: Loss 0.18040980398654938\n",
      "Epoch 47: Loss 0.17695213854312897\n",
      "Epoch 48: Loss 0.17374686896800995\n",
      "Epoch 49: Loss 0.17056059837341309\n",
      "Epoch 50: Loss 0.16765660047531128\n",
      "Epoch 51: Loss 0.16439130902290344\n",
      "Epoch 52: Loss 0.16207173466682434\n",
      "Epoch 53: Loss 0.1593698114156723\n",
      "Epoch 54: Loss 0.1565537005662918\n",
      "Epoch 55: Loss 0.15418054163455963\n",
      "Epoch 56: Loss 0.1519821584224701\n",
      "Epoch 57: Loss 0.14954613149166107\n",
      "Epoch 58: Loss 0.14748942852020264\n",
      "Epoch 59: Loss 0.14539816975593567\n",
      "Epoch 60: Loss 0.14331236481666565\n",
      "Epoch 61: Loss 0.14124473929405212\n",
      "Epoch 62: Loss 0.13923859596252441\n",
      "Epoch 63: Loss 0.13745346665382385\n",
      "Epoch 64: Loss 0.1356058269739151\n",
      "Epoch 65: Loss 0.133889302611351\n",
      "Epoch 66: Loss 0.13207051157951355\n",
      "Epoch 67: Loss 0.1306353062391281\n",
      "Epoch 68: Loss 0.12895788252353668\n",
      "Epoch 69: Loss 0.12740756571292877\n",
      "Epoch 70: Loss 0.12604518234729767\n",
      "Epoch 71: Loss 0.1242981106042862\n",
      "Epoch 72: Loss 0.12326167523860931\n",
      "Epoch 73: Loss 0.12170160561800003\n",
      "Epoch 74: Loss 0.12058264017105103\n",
      "Epoch 75: Loss 0.11917166411876678\n",
      "Epoch 76: Loss 0.11804445087909698\n",
      "Epoch 77: Loss 0.11668835580348969\n",
      "Epoch 78: Loss 0.11563214659690857\n",
      "Epoch 79: Loss 0.11436166614294052\n",
      "Epoch 80: Loss 0.11338011175394058\n",
      "Epoch 81: Loss 0.11232758313417435\n",
      "Epoch 82: Loss 0.11126714944839478\n",
      "Epoch 83: Loss 0.11043708026409149\n",
      "Epoch 84: Loss 0.10925231873989105\n",
      "Epoch 85: Loss 0.10840658098459244\n",
      "Epoch 86: Loss 0.10732114315032959\n",
      "Epoch 87: Loss 0.10662634670734406\n",
      "Epoch 88: Loss 0.10577761381864548\n",
      "Epoch 89: Loss 0.10465946793556213\n",
      "Epoch 90: Loss 0.10411384701728821\n",
      "Epoch 91: Loss 0.10317346453666687\n",
      "Epoch 92: Loss 0.10242868214845657\n",
      "Epoch 93: Loss 0.10150063037872314\n",
      "Epoch 94: Loss 0.10093880444765091\n",
      "Epoch 95: Loss 0.10019341856241226\n",
      "Epoch 96: Loss 0.0996105745434761\n",
      "Epoch 97: Loss 0.0986841470003128\n",
      "Epoch 98: Loss 0.09825073182582855\n",
      "Epoch 99: Loss 0.09761133790016174\n",
      "Epoch 100: Loss 0.09686622023582458\n",
      "Epoch 101: Loss 0.09632953256368637\n",
      "Epoch 102: Loss 0.09564436227083206\n",
      "Epoch 103: Loss 0.09497537463903427\n",
      "Epoch 104: Loss 0.09462077915668488\n",
      "Epoch 105: Loss 0.0938267707824707\n",
      "Epoch 106: Loss 0.0933540090918541\n",
      "Epoch 107: Loss 0.0926973819732666\n",
      "Epoch 108: Loss 0.0923173800110817\n",
      "Epoch 109: Loss 0.09177955985069275\n",
      "Epoch 110: Loss 0.09128755331039429\n",
      "Epoch 111: Loss 0.09073793143033981\n",
      "Epoch 112: Loss 0.09018413722515106\n",
      "Epoch 113: Loss 0.08982538431882858\n",
      "Epoch 114: Loss 0.08920488506555557\n",
      "Epoch 115: Loss 0.0889740064740181\n",
      "Epoch 116: Loss 0.08844982087612152\n",
      "Epoch 117: Loss 0.08806393295526505\n",
      "Epoch 118: Loss 0.08752632141113281\n",
      "Epoch 119: Loss 0.08699528127908707\n",
      "Epoch 120: Loss 0.08677948266267776\n",
      "Epoch 121: Loss 0.08631127327680588\n",
      "Epoch 122: Loss 0.08583894371986389\n",
      "Epoch 123: Loss 0.08549416810274124\n",
      "Epoch 124: Loss 0.08530164510011673\n",
      "Epoch 125: Loss 0.08484380692243576\n",
      "Epoch 126: Loss 0.08454112708568573\n",
      "Epoch 127: Loss 0.0841304287314415\n",
      "Epoch 128: Loss 0.08376939594745636\n",
      "Epoch 129: Loss 0.08344190567731857\n",
      "Epoch 130: Loss 0.08324513584375381\n",
      "Epoch 131: Loss 0.08272048830986023\n",
      "Epoch 132: Loss 0.08250854164361954\n",
      "Epoch 133: Loss 0.08227677643299103\n",
      "Epoch 134: Loss 0.08202139288187027\n",
      "Epoch 135: Loss 0.08156997710466385\n",
      "Epoch 136: Loss 0.08120052516460419\n",
      "Epoch 137: Loss 0.08091143518686295\n",
      "Epoch 138: Loss 0.08063769340515137\n",
      "Epoch 139: Loss 0.08046692609786987\n",
      "Epoch 140: Loss 0.08012521266937256\n",
      "Epoch 141: Loss 0.07996861636638641\n",
      "Epoch 142: Loss 0.079677514731884\n",
      "Epoch 143: Loss 0.0794101282954216\n",
      "Epoch 144: Loss 0.07919032126665115\n",
      "Epoch 145: Loss 0.0788937658071518\n",
      "Epoch 146: Loss 0.07870133221149445\n",
      "Epoch 147: Loss 0.07849834859371185\n",
      "Epoch 148: Loss 0.07814344018697739\n",
      "Epoch 149: Loss 0.07793585956096649\n",
      "Epoch 150: Loss 0.07774020731449127\n",
      "Epoch 151: Loss 0.07748975604772568\n",
      "Epoch 152: Loss 0.07727000117301941\n",
      "Epoch 153: Loss 0.07711738348007202\n",
      "Epoch 154: Loss 0.07688173651695251\n",
      "Epoch 155: Loss 0.07668567448854446\n",
      "Epoch 156: Loss 0.07646974921226501\n",
      "Epoch 157: Loss 0.07613540440797806\n",
      "Epoch 158: Loss 0.07608965784311295\n",
      "Epoch 159: Loss 0.07599204033613205\n",
      "Epoch 160: Loss 0.07563453912734985\n",
      "Epoch 161: Loss 0.07548694312572479\n",
      "Epoch 162: Loss 0.07531934231519699\n",
      "Epoch 163: Loss 0.07507652044296265\n",
      "Epoch 164: Loss 0.07492964714765549\n",
      "Epoch 165: Loss 0.07479704916477203\n",
      "Epoch 166: Loss 0.07468682527542114\n",
      "Epoch 167: Loss 0.0744464099407196\n",
      "Epoch 168: Loss 0.07425706833600998\n",
      "Epoch 169: Loss 0.07409461587667465\n",
      "Epoch 170: Loss 0.07400748133659363\n",
      "Epoch 171: Loss 0.0737551674246788\n",
      "Epoch 172: Loss 0.07368949800729752\n",
      "Epoch 173: Loss 0.07345015555620193\n",
      "Epoch 174: Loss 0.07324555516242981\n",
      "Epoch 175: Loss 0.07323701679706573\n",
      "Epoch 176: Loss 0.07297153025865555\n",
      "Epoch 177: Loss 0.07288523018360138\n",
      "Epoch 178: Loss 0.0727204903960228\n",
      "Epoch 179: Loss 0.07250671833753586\n",
      "Epoch 180: Loss 0.07246224582195282\n",
      "Epoch 181: Loss 0.07241246849298477\n",
      "Epoch 182: Loss 0.07218355685472488\n",
      "Epoch 183: Loss 0.07203848659992218\n",
      "Epoch 184: Loss 0.07197459042072296\n",
      "Epoch 185: Loss 0.07185201346874237\n",
      "Epoch 186: Loss 0.07171177119016647\n",
      "Epoch 187: Loss 0.07155099511146545\n",
      "Epoch 188: Loss 0.07144202291965485\n",
      "Epoch 189: Loss 0.07130368798971176\n",
      "Epoch 190: Loss 0.07114017009735107\n",
      "Epoch 191: Loss 0.0710931345820427\n",
      "Epoch 192: Loss 0.07094288617372513\n",
      "Epoch 193: Loss 0.07087801396846771\n",
      "Epoch 194: Loss 0.07070368528366089\n",
      "Epoch 195: Loss 0.07062119245529175\n",
      "Epoch 196: Loss 0.0705483928322792\n",
      "Epoch 197: Loss 0.07046999037265778\n",
      "Epoch 198: Loss 0.07034244388341904\n",
      "Epoch 199: Loss 0.07023420929908752\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class EdgeWeightedConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeWeightedConv, self).__init__(aggr='add')  # \"add\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # x: [N, in_channels], edge_index: [2, E], edge_weight: [E]\n",
    "        edge_weight = edge_weight.unsqueeze(-1)  # [E, 1]\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, edge_weight=edge_weight)\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        return edge_weight * self.lin(x_j)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = EdgeWeightedConv(num_node_features, hidden_dim)\n",
    "        self.conv2 = EdgeWeightedConv(hidden_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 使用示例\n",
    "model = Net(17, hidden_dim=64).to(device)\n",
    "# 判断是否有GPU\n",
    "data = data.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "# 训练函数\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# 预测函数\n",
    "def predict(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        predictions = torch.softmax(out, dim=1)\n",
    "        return predictions\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(200):\n",
    "    loss = train(model, data, optimizer, criterion)\n",
    "    print(f'Epoch {epoch}: Loss {loss}')\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = predict(model, data)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T03:22:45.625489400Z",
     "start_time": "2023-12-19T03:22:09.385661500Z"
    }
   },
   "id": "6c00bd0b76f92fcb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,roc_auc_score,roc_curve\n",
    "correct=0\n",
    "pred_test=predictions.cpu().numpy()[valid_mask]\n",
    "auc_score=roc_auc_score(y[valid_mask],pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T03:22:47.796136600Z",
     "start_time": "2023-12-19T03:22:47.735616800Z"
    }
   },
   "id": "710f0172030ca193"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prob=torch.nn.functional.softmax(predictions, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-19T02:19:11.776869500Z"
    }
   },
   "id": "405363a725420190"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "pred=predictions.cpu().numpy()[test_mask]\n",
    "pred[:,1]=pred[:,1].astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T09:01:32.366451300Z",
     "start_time": "2023-12-19T09:01:32.326736500Z"
    }
   },
   "id": "f3c2460f92a8af95"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax(dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T02:52:31.722957200Z",
     "start_time": "2023-12-19T02:52:31.344552100Z"
    }
   },
   "id": "be446b30fd2c6f9"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(579157, device='cuda:0')"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions.argmax(dim=1)==0).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T02:52:33.940107800Z",
     "start_time": "2023-12-19T02:52:33.861991600Z"
    }
   },
   "id": "9746a58421f0175f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4939, 2.9809, 0.0000,  ..., 0.0000, 2.4877, 2.3615],\n",
      "        [2.2102, 1.9009, 0.0000,  ..., 0.0000, 2.5485, 1.6243],\n",
      "        [3.0660, 2.6209, 0.0000,  ..., 0.0000, 2.5080, 2.1158],\n",
      "        ...,\n",
      "        [2.6748, 2.2563, 0.0000,  ..., 0.0000, 2.6991, 1.9989],\n",
      "        [4.1165, 3.4914, 0.0000,  ..., 0.0000, 2.9595, 2.7947],\n",
      "        [2.9140, 2.5622, 0.0000,  ..., 0.0000, 0.0000, 2.8049]],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model(data).detach().cpu().numpy()\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T02:22:34.502130900Z",
     "start_time": "2023-12-19T02:22:34.416493100Z"
    }
   },
   "id": "a436f273b8e97ceb"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 551751 is out of bounds for axis 0 with size 193053",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m predy\u001B[38;5;241m=\u001B[39m\u001B[43mpred\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtest_mask\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 551751 is out of bounds for axis 0 with size 193053"
     ]
    }
   ],
   "source": [
    "predy=pred[test_mask]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T02:51:55.706615Z",
     "start_time": "2023-12-19T02:51:55.659747500Z"
    }
   },
   "id": "43a4cbd401089e59"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([], dtype=int64),)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pred[:,0]<0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T02:51:49.464009600Z",
     "start_time": "2023-12-19T02:51:49.409630200Z"
    }
   },
   "id": "82c5b2d95ac3f4c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3069b5b30f72a89d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "result=pd.DataFrame({'index':test_mask,'predict':pred[:,1]})\n",
    "result.to_csv('gcn.csv',index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T09:01:44.426863800Z",
     "start_time": "2023-12-19T09:01:44.156908100Z"
    }
   },
   "id": "d885250f36da319f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
