{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:01.678403700Z",
     "start_time": "2023-12-23T08:57:57.613016600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.1.1+cu118'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:01.696528500Z",
     "start_time": "2023-12-23T08:58:01.679396600Z"
    }
   },
   "id": "89b3c54995539369"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# 加载数据\n",
    "data = np.load('data.npz')\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "edge_index = data['edge_index']\n",
    "train_mask_t= data['train_mask']\n",
    "test_mask = data['test_mask']\n",
    "edge_type = data['edge_type']\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(train_mask_t)\n",
    "train_mask = train_mask_t[:int(len(train_mask_t)/10*8)]\n",
    "valid_mask = train_mask_t[int(len(train_mask_t)/10*8):]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:01.799722900Z",
     "start_time": "2023-12-23T08:58:01.696528500Z"
    }
   },
   "id": "76da579728278043"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:01.815677500Z",
     "start_time": "2023-12-23T08:58:01.800717900Z"
    }
   },
   "id": "fdfbdc1bd0feb055"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int64),\n array([18766,  1758,  2949, 35076, 63909, 26108,   107,  5044,  5589,\n         5493,  2760], dtype=int64))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(edge_type,return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:01.859392100Z",
     "start_time": "2023-12-23T08:58:01.818302300Z"
    }
   },
   "id": "adc9d3e011570666"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 开始特征工程\n",
    "#### 1.节点重要度\n",
    "1.1度中心性\n",
    "$c_D (v)=\\frac{deg(v)}{n-1}$\n",
    "有向图要计算出度中心性和入度中心性"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a5ebd953b4d4a4a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#构造每个节点的入度和出度\n",
    "num_nodes = x.shape[0]\n",
    "in_degree = np.zeros(x.shape[0], dtype=int)\n",
    "out_degree = np.zeros(x.shape[0], dtype=int)\n",
    "for src,dst in edge_index:\n",
    "    in_degree[dst]+=1\n",
    "    out_degree[src]+=1\n",
    "indeg_centrality=in_degree/(num_nodes-1)\n",
    "outdeg_centrality=out_degree/(num_nodes-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:02.106608100Z",
     "start_time": "2023-12-23T08:58:01.831906100Z"
    }
   },
   "id": "5cfd02888bbc4692"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 接近中心性\n",
    "衡量节点影响范围和在信息传播中的作用，是节点到其他节点平均距离的倒数\n",
    "$c_c(v)=\\frac{1}{\\sum_{u\\neq v }d(u,v)}$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0f813e30ceed790"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edge_index)\n",
    "# 计算所有节点对的最短路径长度\n",
    "path_lengths = dict(nx.all_pairs_shortest_path_length(G))\n",
    "closeness_centrality = np.zeros(num_nodes, dtype=float)\n",
    "for node in path_lengths:\n",
    "    total_distance = sum(path_lengths[node].values())\n",
    "    if total_distance > 0:  # 避免除以零\n",
    "        closeness_centrality[node] =1/ total_distance\n",
    "print(closeness_centrality)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:04.110723700Z",
     "start_time": "2023-12-23T08:58:02.109599300Z"
    }
   },
   "id": "e2cdc6cd3d8dd2e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.3 介数中心性\n",
    "指节点在所有最短路径中出现的次数。该指标可以衡量节点在信息传播和资源流动中的作用。\n",
    "$C_B(v)=\\sum_{s\\neq v\\neq t}\\frac{\\sigma(s,t|v)}{\\sigma(s,t)}$\n",
    "其中$\\sigma(s,t)$表示s与t之间的最短路径数，$\\sigma(s,t|v)$表示v在最短路径中出现的次数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb0e7513c2ecc266"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# betweenness_centrality = nx.betweenness_centrality(G)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:04.122692100Z",
     "start_time": "2023-12-23T08:58:04.102758600Z"
    }
   },
   "id": "85f83c36a17cf11a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.4 特征向量重要度\n",
    "指节点的重要性与其相邻节点的重要性有关。如果一个节点与其他重要节点相连，那么它的重要性也会提高。\n",
    "$C_E(v)=\\frac{1}{\\lambda}\\sum_{u\\in N(v)}C_E(u)$\n",
    "其中N(v)表示节点u的邻居节点集合，$\\lambda$是常数，满足$Av=\\lambda v$A是邻接矩阵，v是特征向量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24d45b3072087329"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "eigenvector_centrality = nx.eigenvector_centrality_numpy(G)\n",
    "eigenvector_centrality_array = np.array([eigenvector_centrality.get(node, 0) for node in range(num_nodes)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:05.638016900Z",
     "start_time": "2023-12-23T08:58:04.120696900Z"
    }
   },
   "id": "8d9fda6aac8d3f8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.5 集群系数\n",
    "计算方法为：该节点的周围节点之间相连数 / 该节点与周围节点相连数，值域为[0,1]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf88a6e6982a3304"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#转为无向图计算\n",
    "G_undirected = G.to_undirected()\n",
    "# 计算集群系数\n",
    "clustering_coefficient = nx.clustering(G_undirected)\n",
    "# 将集群系数结果转换为数组形式\n",
    "clustering_coefficient_array = np.array([clustering_coefficient.get(node, 0) for node in range(num_nodes)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:08.486604Z",
     "start_time": "2023-12-23T08:58:05.640989400Z"
    }
   },
   "id": "b94f6330363e702a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.6 pagerank节点相对重要性\n",
    "一个节点向它指向的每个节点“投票”，每个投票的权重是投票者的重要性除以它的出度（即它指向的节点数）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1532e1f343c4386d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.23319579e-06\n",
      " 4.38268035e-06 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "page_rank=nx.pagerank(G, alpha=0.85)\n",
    "pagerank = np.array([page_rank.get(node, 0) for node in range(num_nodes)])\n",
    "\n",
    "# 输出PageRank值\n",
    "print(pagerank)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:09.279339500Z",
     "start_time": "2023-12-23T08:58:08.488598Z"
    }
   },
   "id": "7a250bab27fc61d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.7 katz centrality \n",
    "Katz中心性的定义基于以下思想：节点的重要性是其所有邻居的重要性的总和，但是每条路径的贡献通过一个衰减因子α逐步减少。这个衰减因子α是一个小于网络所有权重的特征值的正数，用来控制路径长度对中心性计算的影响。\n",
    "$C_{\\text{Katz}}(i) = \\sum_{k=1}^{\\infty} \\sum_{j=1}^{n} \\alpha^k \\cdot (A^k)_{ji}$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a1b9dc20f11a030"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "katz_centrality = nx.katz_centrality(G, alpha=0.005)\n",
    "\n",
    "# 将Katz中心性结果转换为数组形式\n",
    "katz_centrality_array = np.array([katz_centrality.get(node, 0) for node in range(num_nodes)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:11.515719Z",
     "start_time": "2023-12-23T08:58:09.275350800Z"
    }
   },
   "id": "923caedad30ba8b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.8 HITS\n",
    "算法是一种用于网络分析的算法，主要用于识别网络中的“权威”（Authorities）和“枢纽”（Hubs）\n",
    "权威（Authorities）：这些是被许多枢纽指向的节点。在互联网环境中，一个权威页面是一个提供特定主题高质量信息的页面，被许多其他页面通过链接引用。\n",
    "枢纽（Hubs）：枢纽是指向多个权威的节点。一个好的枢纽是指一个包含许多权威链接的页面。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a11de8f63c5ebaa"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# # 计算HITS的权威和枢纽分数\n",
    "# hubs, authorities = nx.hits(G)\n",
    "# \n",
    "# # 将结果转换为数组形式\n",
    "# hubs_array = np.array([hubs.get(node, 0) for node in range(max(edge_index.flatten()) + 1)])\n",
    "# authorities_array = np.array([authorities.get(node, 0) for node in range(max(edge_index.flatten()) + 1)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:11.531310200Z",
     "start_time": "2023-12-23T08:58:11.517714Z"
    }
   },
   "id": "709b14c7b1f1eae2"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 计算所有入边的权重和\n",
    "# 初始化节点特征为0（这里假设节点特征是单一值，如果有多维特征，需要调整这里）\n",
    "in_weight=np.zeros(num_nodes,dtype=int)\n",
    "out_weight=np.zeros(num_nodes,dtype=int)\n",
    "# 累加每个节点的所有入边的边类型\n",
    "for i, edge in enumerate(edge_index):\n",
    "    src, dst = edge\n",
    "    in_weight[dst] += edge_type[i]\n",
    "    out_weight[src]+=edge_type[i]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:11.874681200Z",
     "start_time": "2023-12-23T08:58:11.536884200Z"
    }
   },
   "id": "5dff70af20826e6f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "triangle_count = nx.triangles(G_undirected)\n",
    "triangle_count=np.array([triangle_count.get(node, 0) for node in range(num_nodes)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:12.688488100Z",
     "start_time": "2023-12-23T08:58:11.877367600Z"
    }
   },
   "id": "cf4f83801904801a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# # 计算所有可能节点对的杰卡德相似性\n",
    "# jaccard_coefficients = list(nx.jaccard_coefficient(G_undirected))\n",
    "# \n",
    "# # 初始化计数器\n",
    "# count_above_threshold =np.zeros(num_nodes,dtype=int)\n",
    "# \n",
    "# # 对于每个节点对的杰卡德相似性，如果大于阈值，则增加计数\n",
    "# for u, v, coeff in jaccard_coefficients:\n",
    "#     if coeff > 0.5:\n",
    "#         count_above_threshold[u] += 1\n",
    "#         count_above_threshold[v] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:12.705442600Z",
     "start_time": "2023-12-23T08:58:12.690483400Z"
    }
   },
   "id": "a62f4e8551768417"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.社区属性"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb2ce27818266704"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import community as community_louvain\n",
    "\n",
    "# 使用Louvain算法进行社区检测\n",
    "partition = community_louvain.best_partition(G_undirected)\n",
    "community_label=np.array([partition.get(node, 0) for node in range(num_nodes)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:50.457796600Z",
     "start_time": "2023-12-23T08:58:12.707436500Z"
    }
   },
   "id": "5c39ee695eb6ea28"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "constraints = nx.constraint(G)\n",
    "constraint=np.array([constraints.get(node, 0) for node in range(num_nodes)])\n",
    "constraint=np.nan_to_num(constraint,nan=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:58.097300300Z",
     "start_time": "2023-12-23T08:58:50.459792100Z"
    }
   },
   "id": "a9a66393fcbfe4df"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def to_column_vector(arr):\n",
    "    return np.array(arr).reshape(-1, 1)\n",
    "\n",
    "# 将所有特征转换为列向量\n",
    "indeg_col = to_column_vector(indeg_centrality)\n",
    "outdeg_col = to_column_vector(outdeg_centrality)\n",
    "closeness_col = to_column_vector(closeness_centrality)\n",
    "eigenvector_col = to_column_vector(eigenvector_centrality_array)\n",
    "clustering_col = to_column_vector(clustering_coefficient_array)\n",
    "pagerank_col = to_column_vector(pagerank)\n",
    "katz_col = to_column_vector(katz_centrality_array)\n",
    "community_col = to_column_vector(community_label)\n",
    "triangle_col= to_column_vector(triangle_count)\n",
    "in_weight_col=to_column_vector(in_weight)\n",
    "out_weight_col=to_column_vector(out_weight)\n",
    "constraint_col=to_column_vector(constraint)\n",
    "x_train=np.hstack((x,indeg_col,outdeg_col,closeness_col,eigenvector_col,clustering_col,pagerank_col,katz_col,community_col,triangle_col,in_weight_col,out_weight_col,constraint_col))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:58.207752400Z",
     "start_time": "2023-12-23T08:58:58.101290100Z"
    }
   },
   "id": "b5600b5959fffbff"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 对特征矩阵进行标准化\n",
    "x_train = scaler.fit_transform(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:59.155535800Z",
     "start_time": "2023-12-23T08:58:58.209736500Z"
    }
   },
   "id": "24685f28b2a8c382"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 将数据转换为PyTorch张量\n",
    "x_tensor = torch.tensor(x_train, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "edge_index_tensor = torch.tensor(edge_index.T, dtype=torch.long)\n",
    "edge_type_tensor = torch.tensor(edge_type, dtype=torch.long)\n",
    "\n",
    "# 创建掩码\n",
    "num_nodes = x.shape[0]\n",
    "train_mask_tensor = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask_tensor = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask_tensor=torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask_tensor[train_mask] = True\n",
    "test_mask_tensor[test_mask] = True\n",
    "val_mask_tensor[valid_mask]=True\n",
    "# 构造PyTorch Geometric的Data对象\n",
    "data = Data(x=x_tensor, edge_index=edge_index_tensor, edge_type=edge_type_tensor,y=y_tensor)\n",
    "data.train_mask = train_mask_tensor\n",
    "data.test_mask = test_mask_tensor\n",
    "data.val_mask=val_mask_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:59.201412100Z",
     "start_time": "2023-12-23T08:58:59.157530300Z"
    }
   },
   "id": "4792dd183640f74b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Entities\n",
    "from torch_geometric.nn import RGATConv\n",
    "import os.path as osp\n",
    "path = osp.join( './', 'Entities')\n",
    "dataset = Entities(path, 'AIFB')\n",
    "data_demo = dataset[0]\n",
    "data_demo.x = torch.randn(data_demo.num_nodes, 16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:59.203408200Z",
     "start_time": "2023-12-23T08:58:59.188446500Z"
    }
   },
   "id": "7988c411356332a7"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.5699,  0.5517,  1.0438,  ..., -1.2942,  0.5713, -1.0686],\n        [-1.1967, -0.9412,  0.1415,  ...,  1.1197,  0.2940, -0.1127],\n        [-1.5150,  1.7539, -0.9283,  ...,  1.0184, -1.2091, -0.4294],\n        ...,\n        [ 1.3246,  0.1571, -0.1912,  ..., -0.3914, -0.0574,  0.9096],\n        [ 0.6003, -1.5452, -0.1763,  ...,  0.4012, -0.1707,  0.1311],\n        [-0.7009,  0.2053, -1.0368,  ...,  0.6078, -0.5184, -1.2131]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_demo.x[data_demo.train_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:59.232329400Z",
     "start_time": "2023-12-23T08:58:59.203408200Z"
    }
   },
   "id": "d8acbceb7b54874a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.5609,  0.9173, -0.7178,  ..., -0.4412, -0.4761, -0.5409],\n        [-0.5609, -0.5913, -0.7178,  ..., -0.4412, -0.4761, -0.5409],\n        [-0.5609,  0.4144, -0.7178,  ..., -0.4412, -0.4761, -0.5409],\n        ...,\n        [-0.5609,  0.4144,  0.0376,  ..., -0.4412, -0.4761, -0.5409],\n        [ 1.7001, -0.0885, -0.7178,  ..., -0.4412, -0.1416,  2.0200],\n        [ 1.7001, -0.0885,  0.2910,  ..., -0.4412, -0.4761, -0.5409]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x[data.train_mask]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:59.289178300Z",
     "start_time": "2023-12-23T08:58:59.221360200Z"
    }
   },
   "id": "4e22224ca69cbb15"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([308883])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[train_mask].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:58:59.290175900Z",
     "start_time": "2023-12-23T08:58:59.251279Z"
    }
   },
   "id": "982180f668f09218"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGAT(\n",
      "  (conv1): RGATConv(29, 64, heads=1)\n",
      "  (conv2): RGATConv(64, 64, heads=1)\n",
      "  (conv3): RGATConv(64, 32, heads=1)\n",
      "  (lin): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#这个GATv2还有点问题\n",
    "from torch import scatter_add\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, MessagePassing,SAGEConv,GCN2Conv,GATv2Conv,GINConv,RGATConv\n",
    "from torch.nn import Linear, BatchNorm1d, Dropout\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import SAGEConv\n",
    "torch.cuda.empty_cache()\n",
    "num_relations=11\n",
    "class RGAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels,\n",
    "                 num_relations):\n",
    "        super().__init__()\n",
    "        self.conv1 = RGATConv(in_channels, 2*hidden_channels, num_relations)\n",
    "        self.conv2 = RGATConv(2*hidden_channels, 2*hidden_channels, num_relations)\n",
    "        self.conv3 = RGATConv(2*hidden_channels, hidden_channels, num_relations)\n",
    "        self.lin = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x = self.conv1(x, edge_index, edge_type).relu()\n",
    "        x = self.conv2(x, edge_index, edge_type).relu()\n",
    "        x =self.conv3(x, edge_index, edge_type).relu()\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "model = RGAT(data.num_node_features, 32, 2, 12).to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()  # 适用于多类分类任务\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 将数据移动到设备\n",
    "data = data.to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:59:05.743439100Z",
     "start_time": "2023-12-23T08:59:05.600819600Z"
    }
   },
   "id": "163d2d76237a85c2"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.28 GiB. GPU 0 has a total capacty of 6.00 GiB of which 261.55 MiB is free. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 716.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m200\u001B[39m):  \u001B[38;5;66;03m# 可根据需要调整epoch数量\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: Loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(model, data):\n",
      "Cell \u001B[1;32mIn[26], line 4\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      3\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 4\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(out[train_mask], data\u001B[38;5;241m.\u001B[39my[train_mask])\n\u001B[0;32m      6\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[25], line 23\u001B[0m, in \u001B[0;36mRGAT.forward\u001B[1;34m(self, x, edge_index, edge_type)\u001B[0m\n\u001B[0;32m     21\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x, edge_index, edge_type)\u001B[38;5;241m.\u001B[39mrelu()\n\u001B[0;32m     22\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x, edge_index, edge_type)\u001B[38;5;241m.\u001B[39mrelu()\n\u001B[1;32m---> 23\u001B[0m x \u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_type\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mrelu()\n\u001B[0;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin(x)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\conv\\rgat_conv.py:340\u001B[0m, in \u001B[0;36mRGATConv.forward\u001B[1;34m(self, x, edge_index, edge_type, edge_attr, size, return_attention_weights)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Runs the forward pass of the module.\u001B[39;00m\n\u001B[0;32m    319\u001B[0m \n\u001B[0;32m    320\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;124;03m        attention weights for each edge. (default: :obj:`None`)\u001B[39;00m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: Tensor, edge_type: OptTensor, edge_attr: OptTensor)  # noqa\u001B[39;00m\n\u001B[1;32m--> 340\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[43m                     \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    343\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha\n\u001B[0;32m    344\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m alpha \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:463\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    461\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    462\u001B[0m         msg_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 463\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmsg_kwargs)\n\u001B[0;32m    464\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    465\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\conv\\rgat_conv.py:384\u001B[0m, in \u001B[0;36mRGATConv.message\u001B[1;34m(self, x_i, x_j, edge_type, edge_attr, index, ptr, size_i)\u001B[0m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_bases \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    383\u001B[0m     w \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight\n\u001B[1;32m--> 384\u001B[0m w \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex_select\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    385\u001B[0m outi \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbmm(x_i\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m), w)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    386\u001B[0m outj \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbmm(x_j\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m), w)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 1.28 GiB. GPU 0 has a total capacty of 6.00 GiB of which 261.55 MiB is free. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 716.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.edge_type)\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(200):  # 可根据需要调整epoch数量\n",
    "    loss = train()\n",
    "    print(f'Epoch {epoch+1}: Loss {loss:.4f}')\n",
    "\n",
    "\n",
    "def predict(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 确保传递了edge_type参数\n",
    "        out = model(data.x, data.edge_index, data.edge_attr)\n",
    "        predictions = torch.softmax(out, dim=1)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = predict(model, data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T08:59:11.983208700Z",
     "start_time": "2023-12-23T08:59:08.290627200Z"
    }
   },
   "id": "5d4cf373b027f973"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GATConv(29, 128, heads=1)\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): GATConv(128, 128, heads=1)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): GATConv(128, 64, heads=1)\n",
      "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): GATConv(64, 64, heads=1)\n",
      "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): GATConv(64, 64, heads=1)\n",
      "  (bn5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (dropout2): Dropout(p=0.05, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, GATConv, MessagePassing,SAGEConv,GCN2Conv,GATv2Conv,TransformerConv\n",
    "from torch import scatter_add\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, BatchNorm1d, Dropout\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "#SAGE是目前跑出来最好的，GAT其次，GCN最差\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GATConv(data.num_node_features, 2*hidden_channels)\n",
    "        self.bn1 = BatchNorm1d(2*hidden_channels)\n",
    "        self.conv2 =  GATConv(2*hidden_channels, 2*hidden_channels)\n",
    "        self.bn2 = BatchNorm1d(2*hidden_channels)\n",
    "        self.conv3 =  GATConv(2*hidden_channels, hidden_channels)\n",
    "        self.bn3 = BatchNorm1d(hidden_channels)\n",
    "        self.conv4 =  GATConv(hidden_channels, hidden_channels)\n",
    "        self.bn4 = BatchNorm1d(hidden_channels)\n",
    "        self.conv5 =  GATConv(hidden_channels, hidden_channels)\n",
    "        self.bn5 = BatchNorm1d(hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "        self.dropout1 = Dropout(p=0.2)\n",
    "        self.dropout2=Dropout(p=0.05)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x=self.dropout2(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x=self.dropout2(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "        x=self.dropout2(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.bn4(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.bn5(x)\n",
    "        x = x.relu()\n",
    "        x = self.dropout1(x)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data.to(device)\n",
    "model = GCN(hidden_channels=64).to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T05:44:05.072228500Z",
     "start_time": "2023-12-23T05:44:02.424821900Z"
    }
   },
   "id": "58203f9d75d36c03"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 4.42 GiB is allocated by PyTorch, and 221.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 28\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m350\u001B[39m):\n\u001B[1;32m---> 28\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: Loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# 使用模型进行预测\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[21], line 11\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      9\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 11\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(out[train_mask], data\u001B[38;5;241m.\u001B[39my[train_mask])\n\u001B[0;32m     14\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[20], line 47\u001B[0m, in \u001B[0;36mGCN.forward\u001B[1;34m(self, x, edge_index, edge_attr)\u001B[0m\n\u001B[0;32m     45\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn4(x)\n\u001B[0;32m     46\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mrelu()\n\u001B[1;32m---> 47\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv5\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn5(x)\n\u001B[0;32m     49\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mrelu()\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:255\u001B[0m, in \u001B[0;36mGATConv.forward\u001B[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001B[0m\n\u001B[0;32m    252\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39medge_updater(edge_index, alpha\u001B[38;5;241m=\u001B[39malpha, edge_attr\u001B[38;5;241m=\u001B[39medge_attr)\n\u001B[0;32m    254\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001B[39;00m\n\u001B[1;32m--> 255\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconcat:\n\u001B[0;32m    258\u001B[0m     out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheads \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_channels)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:480\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    477\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    478\u001B[0m         aggr_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 480\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate(out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39maggr_kwargs)\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aggregate_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    483\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (aggr_kwargs, ), out)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:604\u001B[0m, in \u001B[0;36mMessagePassing.aggregate\u001B[1;34m(self, inputs, index, ptr, dim_size)\u001B[0m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maggregate\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: Tensor, index: Tensor,\n\u001B[0;32m    592\u001B[0m               ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    593\u001B[0m               dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    594\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001B[39;00m\n\u001B[0;32m    595\u001B[0m \u001B[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001B[39;00m\n\u001B[0;32m    596\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    602\u001B[0m \u001B[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001B[39;00m\n\u001B[0;32m    603\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 604\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggr_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    605\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\experimental.py:115\u001B[0m, in \u001B[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_experimental_mode_enabled(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisable_dynamic_shapes\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m required_arg \u001B[38;5;129;01min\u001B[39;00m required_args:\n\u001B[0;32m    118\u001B[0m         index \u001B[38;5;241m=\u001B[39m required_args_pos[required_arg]\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:133\u001B[0m, in \u001B[0;36mAggregation.__call__\u001B[1;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001B[0m\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dim_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()):\n\u001B[0;32m    130\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered invalid \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdim_size\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    131\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdim_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m but expected \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    132\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>= \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax())\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 133\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:125\u001B[0m, in \u001B[0;36mAggregation.__call__\u001B[1;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001B[0m\n\u001B[0;32m    122\u001B[0m     dim_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(x, index\u001B[38;5;241m=\u001B[39mindex, ptr\u001B[38;5;241m=\u001B[39mptr, dim_size\u001B[38;5;241m=\u001B[39mdim_size,\n\u001B[0;32m    126\u001B[0m                             dim\u001B[38;5;241m=\u001B[39mdim, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mIndexError\u001B[39;00m, \u001B[38;5;167;01mRuntimeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\aggr\\basic.py:22\u001B[0m, in \u001B[0;36mSumAggregation.forward\u001B[1;34m(self, x, index, ptr, dim_size, dim)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor, index: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     20\u001B[0m             ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     21\u001B[0m             dim: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m---> 22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:176\u001B[0m, in \u001B[0;36mAggregation.reduce\u001B[1;34m(self, x, index, ptr, dim_size, dim, reduce)\u001B[0m\n\u001B[0;32m    173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m segment(x, ptr, reduce\u001B[38;5;241m=\u001B[39mreduce)\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch_geometric\\utils\\scatter.py:70\u001B[0m, in \u001B[0;36mscatter\u001B[1;34m(src, index, dim, dim_size, reduce)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     69\u001B[0m     index \u001B[38;5;241m=\u001B[39m broadcast(index, src, dim)\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_zeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mscatter_add_(dim, index, src)\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     73\u001B[0m     count \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mnew_zeros(dim_size)\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 4.42 GiB is allocated by PyTorch, and 221.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练函数\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x, data.edge_index,data.edge_attr)\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# 预测函数\n",
    "def predict(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x,data.edge_index,data.edge_attr)\n",
    "        predictions = torch.softmax(out, dim=1)\n",
    "        return predictions\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(350):\n",
    "    loss = train()\n",
    "    print(f'Epoch {epoch}: Loss {loss}')\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = predict(model, data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T05:44:08.492658100Z",
     "start_time": "2023-12-23T05:44:05.070234600Z"
    }
   },
   "id": "60d51c59d5992623"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 构造测试集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "387cd34435347fb8"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7333391906653455"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用valdata本地测一下分数\n",
    "from sklearn.metrics import auc,roc_auc_score,roc_curve\n",
    "correct=0\n",
    "pred_test=predictions.cpu().numpy()[valid_mask]\n",
    "auc_score=roc_auc_score(y[valid_mask],pred_test[:,1])\n",
    "auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T05:37:28.249868600Z",
     "start_time": "2023-12-23T05:37:28.209985500Z"
    }
   },
   "id": "61dd6a13cb22c89f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 1.4810748100280762\n",
      "Epoch 1: Loss 0.5523459315299988\n",
      "Epoch 2: Loss 0.5455896258354187\n",
      "Epoch 3: Loss 0.5382967591285706\n",
      "Epoch 4: Loss 0.5338159203529358\n",
      "Epoch 5: Loss 0.5285800695419312\n",
      "Epoch 6: Loss 0.5176761150360107\n",
      "Epoch 7: Loss 0.5037001371383667\n",
      "Epoch 8: Loss 0.48367154598236084\n",
      "Epoch 9: Loss 0.46988195180892944\n",
      "Epoch 10: Loss 0.4525890350341797\n",
      "Epoch 11: Loss 0.4334716200828552\n",
      "Epoch 12: Loss 0.4127180278301239\n",
      "Epoch 13: Loss 0.39623966813087463\n",
      "Epoch 14: Loss 0.37849104404449463\n",
      "Epoch 15: Loss 0.36127474904060364\n",
      "Epoch 16: Loss 0.34692028164863586\n",
      "Epoch 17: Loss 0.3384524881839752\n",
      "Epoch 18: Loss 0.33358246088027954\n",
      "Epoch 19: Loss 0.3263548016548157\n",
      "Epoch 20: Loss 0.31523656845092773\n",
      "Epoch 21: Loss 0.3050832450389862\n",
      "Epoch 22: Loss 0.29544883966445923\n",
      "Epoch 23: Loss 0.28744494915008545\n",
      "Epoch 24: Loss 0.27970683574676514\n",
      "Epoch 25: Loss 0.27338606119155884\n",
      "Epoch 26: Loss 0.2675369381904602\n",
      "Epoch 27: Loss 0.2599165141582489\n",
      "Epoch 28: Loss 0.25341030955314636\n",
      "Epoch 29: Loss 0.2473253458738327\n",
      "Epoch 30: Loss 0.24181821942329407\n",
      "Epoch 31: Loss 0.2351246327161789\n",
      "Epoch 32: Loss 0.23052392899990082\n",
      "Epoch 33: Loss 0.2233511358499527\n",
      "Epoch 34: Loss 0.21825917065143585\n",
      "Epoch 35: Loss 0.21323393285274506\n",
      "Epoch 36: Loss 0.20790863037109375\n",
      "Epoch 37: Loss 0.20380453765392303\n",
      "Epoch 38: Loss 0.19957521557807922\n",
      "Epoch 39: Loss 0.19555141031742096\n",
      "Epoch 40: Loss 0.19138190150260925\n",
      "Epoch 41: Loss 0.18702499568462372\n",
      "Epoch 42: Loss 0.18351997435092926\n",
      "Epoch 43: Loss 0.18053650856018066\n",
      "Epoch 44: Loss 0.17640842497348785\n",
      "Epoch 45: Loss 0.17286233603954315\n",
      "Epoch 46: Loss 0.17010597884655\n",
      "Epoch 47: Loss 0.16689401865005493\n",
      "Epoch 48: Loss 0.16421900689601898\n",
      "Epoch 49: Loss 0.1614670604467392\n",
      "Epoch 50: Loss 0.1587596982717514\n",
      "Epoch 51: Loss 0.1559763252735138\n",
      "Epoch 52: Loss 0.15331560373306274\n",
      "Epoch 53: Loss 0.15074872970581055\n",
      "Epoch 54: Loss 0.14846056699752808\n",
      "Epoch 55: Loss 0.14624351263046265\n",
      "Epoch 56: Loss 0.14402903616428375\n",
      "Epoch 57: Loss 0.1425841897726059\n",
      "Epoch 58: Loss 0.13985644280910492\n",
      "Epoch 59: Loss 0.13824288547039032\n",
      "Epoch 60: Loss 0.13613350689411163\n",
      "Epoch 61: Loss 0.1340489387512207\n",
      "Epoch 62: Loss 0.13265059888362885\n",
      "Epoch 63: Loss 0.13141413033008575\n",
      "Epoch 64: Loss 0.1292000412940979\n",
      "Epoch 65: Loss 0.12769147753715515\n",
      "Epoch 66: Loss 0.12605638802051544\n",
      "Epoch 67: Loss 0.12464769929647446\n",
      "Epoch 68: Loss 0.12290456146001816\n",
      "Epoch 69: Loss 0.12197970598936081\n",
      "Epoch 70: Loss 0.12045197188854218\n",
      "Epoch 71: Loss 0.11918465048074722\n",
      "Epoch 72: Loss 0.11789673566818237\n",
      "Epoch 73: Loss 0.11675849556922913\n",
      "Epoch 74: Loss 0.1156276986002922\n",
      "Epoch 75: Loss 0.11440761387348175\n",
      "Epoch 76: Loss 0.11329486966133118\n",
      "Epoch 77: Loss 0.11183098703622818\n",
      "Epoch 78: Loss 0.11114735156297684\n",
      "Epoch 79: Loss 0.10987111926078796\n",
      "Epoch 80: Loss 0.10871101170778275\n",
      "Epoch 81: Loss 0.10792883485555649\n",
      "Epoch 82: Loss 0.10720037668943405\n",
      "Epoch 83: Loss 0.10613448172807693\n",
      "Epoch 84: Loss 0.10531643778085709\n",
      "Epoch 85: Loss 0.10457001626491547\n",
      "Epoch 86: Loss 0.10357791185379028\n",
      "Epoch 87: Loss 0.10282610356807709\n",
      "Epoch 88: Loss 0.1019238755106926\n",
      "Epoch 89: Loss 0.1011565774679184\n",
      "Epoch 90: Loss 0.1004336029291153\n",
      "Epoch 91: Loss 0.10004016757011414\n",
      "Epoch 92: Loss 0.09902410209178925\n",
      "Epoch 93: Loss 0.09836340695619583\n",
      "Epoch 94: Loss 0.09758597612380981\n",
      "Epoch 95: Loss 0.0969289168715477\n",
      "Epoch 96: Loss 0.09627097100019455\n",
      "Epoch 97: Loss 0.09573142975568771\n",
      "Epoch 98: Loss 0.095010906457901\n",
      "Epoch 99: Loss 0.09457837790250778\n",
      "Epoch 100: Loss 0.09377578645944595\n",
      "Epoch 101: Loss 0.09342208504676819\n",
      "Epoch 102: Loss 0.09262526035308838\n",
      "Epoch 103: Loss 0.09223147481679916\n",
      "Epoch 104: Loss 0.09157706052064896\n",
      "Epoch 105: Loss 0.09144391119480133\n",
      "Epoch 106: Loss 0.09051664918661118\n",
      "Epoch 107: Loss 0.09022940695285797\n",
      "Epoch 108: Loss 0.08976201713085175\n",
      "Epoch 109: Loss 0.08919686824083328\n",
      "Epoch 110: Loss 0.08879854530096054\n",
      "Epoch 111: Loss 0.08823931962251663\n",
      "Epoch 112: Loss 0.08776941895484924\n",
      "Epoch 113: Loss 0.08731518685817719\n",
      "Epoch 114: Loss 0.08691678196191788\n",
      "Epoch 115: Loss 0.08654753863811493\n",
      "Epoch 116: Loss 0.08618757128715515\n",
      "Epoch 117: Loss 0.08586616814136505\n",
      "Epoch 118: Loss 0.08549540489912033\n",
      "Epoch 119: Loss 0.0851348266005516\n",
      "Epoch 120: Loss 0.08472558110952377\n",
      "Epoch 121: Loss 0.08433357626199722\n",
      "Epoch 122: Loss 0.08383756130933762\n",
      "Epoch 123: Loss 0.08357681334018707\n",
      "Epoch 124: Loss 0.08332673460245132\n",
      "Epoch 125: Loss 0.08290158212184906\n",
      "Epoch 126: Loss 0.0827566385269165\n",
      "Epoch 127: Loss 0.08220139890909195\n",
      "Epoch 128: Loss 0.08210047334432602\n",
      "Epoch 129: Loss 0.08173730969429016\n",
      "Epoch 130: Loss 0.08147187530994415\n",
      "Epoch 131: Loss 0.0810740664601326\n",
      "Epoch 132: Loss 0.08076518774032593\n",
      "Epoch 133: Loss 0.0804014801979065\n",
      "Epoch 134: Loss 0.08013167977333069\n",
      "Epoch 135: Loss 0.07992388308048248\n",
      "Epoch 136: Loss 0.07966449111700058\n",
      "Epoch 137: Loss 0.0792938619852066\n",
      "Epoch 138: Loss 0.07914237678050995\n",
      "Epoch 139: Loss 0.0788126289844513\n",
      "Epoch 140: Loss 0.07872769236564636\n",
      "Epoch 141: Loss 0.07841864228248596\n",
      "Epoch 142: Loss 0.07801585644483566\n",
      "Epoch 143: Loss 0.07791529595851898\n",
      "Epoch 144: Loss 0.07760874927043915\n",
      "Epoch 145: Loss 0.07740070670843124\n",
      "Epoch 146: Loss 0.07722023129463196\n",
      "Epoch 147: Loss 0.07708494365215302\n",
      "Epoch 148: Loss 0.07680230587720871\n",
      "Epoch 149: Loss 0.07656742632389069\n",
      "Epoch 150: Loss 0.07641733437776566\n",
      "Epoch 151: Loss 0.07611853629350662\n",
      "Epoch 152: Loss 0.07584540545940399\n",
      "Epoch 153: Loss 0.07579244673252106\n",
      "Epoch 154: Loss 0.07559242099523544\n",
      "Epoch 155: Loss 0.07536280155181885\n",
      "Epoch 156: Loss 0.07519533485174179\n",
      "Epoch 157: Loss 0.07505553215742111\n",
      "Epoch 158: Loss 0.0749066174030304\n",
      "Epoch 159: Loss 0.07465256750583649\n",
      "Epoch 160: Loss 0.0745752602815628\n",
      "Epoch 161: Loss 0.07434286922216415\n",
      "Epoch 162: Loss 0.07421797513961792\n",
      "Epoch 163: Loss 0.0739554613828659\n",
      "Epoch 164: Loss 0.07383295148611069\n",
      "Epoch 165: Loss 0.07366026937961578\n",
      "Epoch 166: Loss 0.07347758114337921\n",
      "Epoch 167: Loss 0.07334970682859421\n",
      "Epoch 168: Loss 0.07316911220550537\n",
      "Epoch 169: Loss 0.07303709536790848\n",
      "Epoch 170: Loss 0.07290798425674438\n",
      "Epoch 171: Loss 0.07274042814970016\n",
      "Epoch 172: Loss 0.07261018455028534\n",
      "Epoch 173: Loss 0.07236126810312271\n",
      "Epoch 174: Loss 0.07237134128808975\n",
      "Epoch 175: Loss 0.07233239710330963\n",
      "Epoch 176: Loss 0.07208555191755295\n",
      "Epoch 177: Loss 0.07197079062461853\n",
      "Epoch 178: Loss 0.07176599651575089\n",
      "Epoch 179: Loss 0.0717780664563179\n",
      "Epoch 180: Loss 0.07164467871189117\n",
      "Epoch 181: Loss 0.07156600058078766\n",
      "Epoch 182: Loss 0.07141304761171341\n",
      "Epoch 183: Loss 0.07120254635810852\n",
      "Epoch 184: Loss 0.07111471891403198\n",
      "Epoch 185: Loss 0.07100649178028107\n",
      "Epoch 186: Loss 0.07095857709646225\n",
      "Epoch 187: Loss 0.0707830935716629\n",
      "Epoch 188: Loss 0.07066439092159271\n",
      "Epoch 189: Loss 0.07057464867830276\n",
      "Epoch 190: Loss 0.07044926285743713\n",
      "Epoch 191: Loss 0.07038851082324982\n",
      "Epoch 192: Loss 0.07021908462047577\n",
      "Epoch 193: Loss 0.07009237259626389\n",
      "Epoch 194: Loss 0.0700359046459198\n",
      "Epoch 195: Loss 0.06994353234767914\n",
      "Epoch 196: Loss 0.06980304419994354\n",
      "Epoch 197: Loss 0.06982627511024475\n",
      "Epoch 198: Loss 0.06966561079025269\n",
      "Epoch 199: Loss 0.06952985376119614\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class EdgeWeightedConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeWeightedConv, self).__init__(aggr='add')  # \"add\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # x: [N, in_channels], edge_index: [2, E], edge_weight: [E]\n",
    "        edge_weight = edge_weight.unsqueeze(-1)  # [E, 1]\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, edge_weight=edge_weight)\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        return edge_weight * self.lin(x_j)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = EdgeWeightedConv(num_node_features, hidden_dim)\n",
    "        self.conv2 = EdgeWeightedConv(hidden_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 使用示例\n",
    "model = Net(17, hidden_dim=64).to(device)\n",
    "# 判断是否有GPU\n",
    "data = data.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "# 训练函数\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# 预测函数\n",
    "def predict(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        predictions = torch.softmax(out, dim=1)\n",
    "        return predictions\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(200):\n",
    "    loss = train(model, data, optimizer, criterion)\n",
    "    print(f'Epoch {epoch}: Loss {loss}')\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = predict(model, data)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T07:03:57.780873800Z",
     "start_time": "2023-12-22T07:03:50.974107600Z"
    }
   },
   "id": "6c00bd0b76f92fcb"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,roc_auc_score,roc_curve\n",
    "correct=0\n",
    "pred_test=predictions.cpu().numpy()[valid_mask]\n",
    "auc_score=roc_auc_score(y[valid_mask],pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T17:14:07.999463100Z",
     "start_time": "2023-12-22T17:14:07.948255400Z"
    }
   },
   "id": "710f0172030ca193"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prob=torch.nn.functional.softmax(predictions, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-19T02:19:11.776869500Z"
    }
   },
   "id": "405363a725420190"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "pred=predictions.cpu().numpy()[test_mask]\n",
    "pred[:,1]=pred[:,1].astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T17:27:48.709702100Z",
     "start_time": "2023-12-22T17:27:48.666986200Z"
    }
   },
   "id": "f3c2460f92a8af95"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax(dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T02:52:31.722957200Z",
     "start_time": "2023-12-19T02:52:31.344552100Z"
    }
   },
   "id": "be446b30fd2c6f9"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(579157, device='cuda:0')"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions.argmax(dim=1)==0).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T02:52:33.940107800Z",
     "start_time": "2023-12-19T02:52:33.861991600Z"
    }
   },
   "id": "9746a58421f0175f"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GCN.forward() missing 2 required positional arguments: 'edge_index' and 'edge_attr'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m      2\u001B[0m y\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\risk-control\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: GCN.forward() missing 2 required positional arguments: 'edge_index' and 'edge_attr'"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model(data).detach().cpu().numpy()\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T16:55:06.574238400Z",
     "start_time": "2023-12-22T16:55:05.355101900Z"
    }
   },
   "id": "a436f273b8e97ceb"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 551751 is out of bounds for axis 0 with size 193053",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m predy\u001B[38;5;241m=\u001B[39m\u001B[43mpred\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtest_mask\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[1;31mIndexError\u001B[0m: index 551751 is out of bounds for axis 0 with size 193053"
     ]
    }
   ],
   "source": [
    "predy=pred[test_mask]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T02:51:55.706615Z",
     "start_time": "2023-12-19T02:51:55.659747500Z"
    }
   },
   "id": "43a4cbd401089e59"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([], dtype=int64),)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pred[:,0]<0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T02:51:49.464009600Z",
     "start_time": "2023-12-19T02:51:49.409630200Z"
    }
   },
   "id": "82c5b2d95ac3f4c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3069b5b30f72a89d"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "result=pd.DataFrame({'index':test_mask,'predict':pred[:,1]})\n",
    "result.to_csv('gcn.csv',index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T17:27:52.401963800Z",
     "start_time": "2023-12-22T17:27:52.120949700Z"
    }
   },
   "id": "d885250f36da319f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
