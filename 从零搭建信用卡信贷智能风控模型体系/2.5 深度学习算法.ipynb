{"cells":[{"cell_type":"markdown","metadata":{"trusted":true,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"D89B0EAB542642F98900CCC4D4E49360","runtime":{"status":"default","execution_status":null,"is_visible":false},"scrolled":false,"notebookId":"6515d257d40e0c1a5867aec8"},"source":"## Deep Learning    \n\n### 在风控领域，深度学习算法多使用在特征挖掘方面  \n\n### 运行时选择【**风控专用镜像（TensorFlow 2.6）**】  \n"},{"cell_type":"markdown","metadata":{"id":"1B284D1F23DD4E0697839FAAE1BABDE4","notebookId":"6515d257d40e0c1a5867aec8","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"## 1. 深度神经网络DNN"},{"cell_type":"code","metadata":{"id":"810CF482643D4985AFA558B9F60AF78D","notebookId":"6515d257d40e0c1a5867aec8","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"source":"# https://keras.io\n\nimport tensorflow as tf\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras import layers, models, callbacks\n\nfrom utils import data_utils\n\n# 加载数据集\ntrain_x, test_x, train_y, test_y = data_utils.get_x_y_split(transform_method='standard')\n\n# 设置随机数种子\ntf.random.set_seed(1)\n\n# 设置早停\ncallback = callbacks.EarlyStopping(monitor='val_loss', patience=30, mode='min')\n\n# 构建DNN模型结构\nmodel = models.Sequential()\nmodel.add(layers.Flatten(input_shape=(train_x.shape[1], 1)))\nmodel.add(layers.Dense(32, activation=tf.nn.relu))\nmodel.add(layers.Dropout(0.3, seed=1))\nmodel.add(layers.Dense(16, activation=tf.nn.relu))\nmodel.add(layers.Dense(1, activation=tf.nn.sigmoid))\n# 显示模型的结构\nmodel.summary()\n\n# 设置模型训练参数\nmodel.compile(optimizer='SGD',\n              metrics=[tf.metrics.AUC()],\n              loss='binary_crossentropy')\n# 模型训练\nmodel.fit(train_x, train_y, validation_data=(test_x, test_y), batch_size=16, epochs=240, callbacks=[callback], verbose=2)\n\n# 效果评估\nauc_score = roc_auc_score(train_y, model.predict(train_x))\nprint(\"训练集AUC\", auc_score)\nauc_score = roc_auc_score(test_y, model.predict(test_x))\nprint(\"测试集AUC\", auc_score)\n","outputs":[{"output_type":"stream","name":"stderr","text":"2023-09-29 13:15:21.539234: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"},{"output_type":"stream","name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 20)                0         \n_________________________________________________________________\ndense (Dense)                (None, 32)                672       \n_________________________________________________________________\ndropout (Dropout)            (None, 32)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                528       \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 1,217\nTrainable params: 1,217\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/240\n"},{"output_type":"stream","name":"stderr","text":"2023-09-29 13:15:21.763791: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"},{"output_type":"stream","name":"stdout","text":"50/50 - 1s - loss: 0.6823 - auc: 0.5344 - val_loss: 0.6309 - val_auc: 0.5800\nEpoch 2/240\n50/50 - 0s - loss: 0.6460 - auc: 0.5390 - val_loss: 0.6061 - val_auc: 0.5920\nEpoch 3/240\n50/50 - 0s - loss: 0.6360 - auc: 0.5312 - val_loss: 0.5912 - val_auc: 0.6107\nEpoch 4/240\n50/50 - 0s - loss: 0.6203 - auc: 0.5646 - val_loss: 0.5812 - val_auc: 0.6252\nEpoch 5/240\n50/50 - 0s - loss: 0.6068 - auc: 0.5951 - val_loss: 0.5746 - val_auc: 0.6353\nEpoch 6/240\n50/50 - 0s - loss: 0.5950 - auc: 0.6233 - val_loss: 0.5677 - val_auc: 0.6440\nEpoch 7/240\n50/50 - 0s - loss: 0.5890 - auc: 0.6395 - val_loss: 0.5624 - val_auc: 0.6590\nEpoch 8/240\n50/50 - 0s - loss: 0.5838 - auc: 0.6687 - val_loss: 0.5572 - val_auc: 0.6672\nEpoch 9/240\n50/50 - 0s - loss: 0.5864 - auc: 0.6489 - val_loss: 0.5533 - val_auc: 0.6742\nEpoch 10/240\n50/50 - 0s - loss: 0.5719 - auc: 0.6839 - val_loss: 0.5486 - val_auc: 0.6788\nEpoch 11/240\n50/50 - 0s - loss: 0.5691 - auc: 0.6821 - val_loss: 0.5452 - val_auc: 0.6887\nEpoch 12/240\n50/50 - 0s - loss: 0.5611 - auc: 0.7069 - val_loss: 0.5414 - val_auc: 0.6967\nEpoch 13/240\n50/50 - 0s - loss: 0.5508 - auc: 0.7183 - val_loss: 0.5371 - val_auc: 0.7026\nEpoch 14/240\n50/50 - 0s - loss: 0.5583 - auc: 0.7091 - val_loss: 0.5337 - val_auc: 0.7075\nEpoch 15/240\n50/50 - 0s - loss: 0.5607 - auc: 0.7001 - val_loss: 0.5310 - val_auc: 0.7138\nEpoch 16/240\n50/50 - 0s - loss: 0.5545 - auc: 0.7227 - val_loss: 0.5286 - val_auc: 0.7154\nEpoch 17/240\n50/50 - 0s - loss: 0.5610 - auc: 0.7018 - val_loss: 0.5268 - val_auc: 0.7184\nEpoch 18/240\n50/50 - 0s - loss: 0.5419 - auc: 0.7384 - val_loss: 0.5243 - val_auc: 0.7223\nEpoch 19/240\n50/50 - 0s - loss: 0.5430 - auc: 0.7265 - val_loss: 0.5223 - val_auc: 0.7264\nEpoch 20/240\n50/50 - 0s - loss: 0.5389 - auc: 0.7343 - val_loss: 0.5206 - val_auc: 0.7282\nEpoch 21/240\n50/50 - 0s - loss: 0.5471 - auc: 0.7208 - val_loss: 0.5189 - val_auc: 0.7298\nEpoch 22/240\n50/50 - 0s - loss: 0.5295 - auc: 0.7519 - val_loss: 0.5172 - val_auc: 0.7315\nEpoch 23/240\n50/50 - 0s - loss: 0.5335 - auc: 0.7447 - val_loss: 0.5156 - val_auc: 0.7346\nEpoch 24/240\n50/50 - 0s - loss: 0.5313 - auc: 0.7482 - val_loss: 0.5141 - val_auc: 0.7368\nEpoch 25/240\n50/50 - 0s - loss: 0.5199 - auc: 0.7635 - val_loss: 0.5124 - val_auc: 0.7377\nEpoch 26/240\n50/50 - 0s - loss: 0.5281 - auc: 0.7495 - val_loss: 0.5115 - val_auc: 0.7388\nEpoch 27/240\n50/50 - 0s - loss: 0.5215 - auc: 0.7606 - val_loss: 0.5103 - val_auc: 0.7418\nEpoch 28/240\n50/50 - 0s - loss: 0.5170 - auc: 0.7675 - val_loss: 0.5094 - val_auc: 0.7406\nEpoch 29/240\n50/50 - 0s - loss: 0.5221 - auc: 0.7592 - val_loss: 0.5092 - val_auc: 0.7408\nEpoch 30/240\n50/50 - 0s - loss: 0.5311 - auc: 0.7521 - val_loss: 0.5086 - val_auc: 0.7428\nEpoch 31/240\n50/50 - 0s - loss: 0.5344 - auc: 0.7423 - val_loss: 0.5082 - val_auc: 0.7445\nEpoch 32/240\n50/50 - 0s - loss: 0.5071 - auc: 0.7776 - val_loss: 0.5073 - val_auc: 0.7455\nEpoch 33/240\n50/50 - 0s - loss: 0.5219 - auc: 0.7587 - val_loss: 0.5067 - val_auc: 0.7463\nEpoch 34/240\n50/50 - 0s - loss: 0.5171 - auc: 0.7653 - val_loss: 0.5062 - val_auc: 0.7478\nEpoch 35/240\n50/50 - 0s - loss: 0.5122 - auc: 0.7735 - val_loss: 0.5060 - val_auc: 0.7480\nEpoch 36/240\n50/50 - 0s - loss: 0.5103 - auc: 0.7703 - val_loss: 0.5058 - val_auc: 0.7475\nEpoch 37/240\n50/50 - 0s - loss: 0.5177 - auc: 0.7665 - val_loss: 0.5056 - val_auc: 0.7476\nEpoch 38/240\n50/50 - 0s - loss: 0.5112 - auc: 0.7760 - val_loss: 0.5053 - val_auc: 0.7463\nEpoch 39/240\n50/50 - 0s - loss: 0.5108 - auc: 0.7768 - val_loss: 0.5049 - val_auc: 0.7461\nEpoch 40/240\n50/50 - 0s - loss: 0.5091 - auc: 0.7747 - val_loss: 0.5048 - val_auc: 0.7470\nEpoch 41/240\n50/50 - 0s - loss: 0.4960 - auc: 0.7909 - val_loss: 0.5043 - val_auc: 0.7477\nEpoch 42/240\n50/50 - 0s - loss: 0.4947 - auc: 0.7894 - val_loss: 0.5036 - val_auc: 0.7484\nEpoch 43/240\n50/50 - 0s - loss: 0.5031 - auc: 0.7868 - val_loss: 0.5035 - val_auc: 0.7491\nEpoch 44/240\n50/50 - 0s - loss: 0.4908 - auc: 0.7943 - val_loss: 0.5031 - val_auc: 0.7497\nEpoch 45/240\n50/50 - 0s - loss: 0.5091 - auc: 0.7768 - val_loss: 0.5031 - val_auc: 0.7501\nEpoch 46/240\n50/50 - 0s - loss: 0.5061 - auc: 0.7857 - val_loss: 0.5032 - val_auc: 0.7495\nEpoch 47/240\n50/50 - 0s - loss: 0.4984 - auc: 0.7888 - val_loss: 0.5028 - val_auc: 0.7508\nEpoch 48/240\n50/50 - 0s - loss: 0.4856 - auc: 0.8027 - val_loss: 0.5036 - val_auc: 0.7490\nEpoch 49/240\n50/50 - 0s - loss: 0.4913 - auc: 0.7985 - val_loss: 0.5036 - val_auc: 0.7501\nEpoch 50/240\n50/50 - 0s - loss: 0.4966 - auc: 0.7934 - val_loss: 0.5039 - val_auc: 0.7498\nEpoch 51/240\n50/50 - 0s - loss: 0.4925 - auc: 0.7931 - val_loss: 0.5041 - val_auc: 0.7489\nEpoch 52/240\n50/50 - 0s - loss: 0.5059 - auc: 0.7806 - val_loss: 0.5036 - val_auc: 0.7494\nEpoch 53/240\n50/50 - 0s - loss: 0.4959 - auc: 0.7944 - val_loss: 0.5039 - val_auc: 0.7503\nEpoch 54/240\n50/50 - 0s - loss: 0.4930 - auc: 0.7934 - val_loss: 0.5046 - val_auc: 0.7471\nEpoch 55/240\n50/50 - 0s - loss: 0.4899 - auc: 0.7945 - val_loss: 0.5048 - val_auc: 0.7479\nEpoch 56/240\n50/50 - 0s - loss: 0.4812 - auc: 0.8050 - val_loss: 0.5052 - val_auc: 0.7476\nEpoch 57/240\n50/50 - 0s - loss: 0.4843 - auc: 0.8041 - val_loss: 0.5047 - val_auc: 0.7485\nEpoch 58/240\n50/50 - 0s - loss: 0.4790 - auc: 0.8101 - val_loss: 0.5042 - val_auc: 0.7494\nEpoch 59/240\n50/50 - 0s - loss: 0.4822 - auc: 0.8052 - val_loss: 0.5042 - val_auc: 0.7498\nEpoch 60/240\n50/50 - 0s - loss: 0.4707 - auc: 0.8170 - val_loss: 0.5047 - val_auc: 0.7501\nEpoch 61/240\n50/50 - 0s - loss: 0.4860 - auc: 0.7967 - val_loss: 0.5047 - val_auc: 0.7504\nEpoch 62/240\n50/50 - 0s - loss: 0.4768 - auc: 0.8117 - val_loss: 0.5042 - val_auc: 0.7511\nEpoch 63/240\n50/50 - 0s - loss: 0.4825 - auc: 0.8054 - val_loss: 0.5039 - val_auc: 0.7506\nEpoch 64/240\n50/50 - 0s - loss: 0.4793 - auc: 0.8076 - val_loss: 0.5039 - val_auc: 0.7511\nEpoch 65/240\n50/50 - 0s - loss: 0.4788 - auc: 0.8078 - val_loss: 0.5045 - val_auc: 0.7502\nEpoch 66/240\n50/50 - 0s - loss: 0.4830 - auc: 0.8026 - val_loss: 0.5045 - val_auc: 0.7494\nEpoch 67/240\n50/50 - 0s - loss: 0.4815 - auc: 0.8039 - val_loss: 0.5046 - val_auc: 0.7501\nEpoch 68/240\n50/50 - 0s - loss: 0.4694 - auc: 0.8217 - val_loss: 0.5048 - val_auc: 0.7503\nEpoch 69/240\n50/50 - 0s - loss: 0.4810 - auc: 0.8063 - val_loss: 0.5054 - val_auc: 0.7498\nEpoch 70/240\n50/50 - 0s - loss: 0.4734 - auc: 0.8115 - val_loss: 0.5050 - val_auc: 0.7502\nEpoch 71/240\n50/50 - 0s - loss: 0.4871 - auc: 0.7977 - val_loss: 0.5048 - val_auc: 0.7512\nEpoch 72/240\n50/50 - 0s - loss: 0.4739 - auc: 0.8108 - val_loss: 0.5053 - val_auc: 0.7504\nEpoch 73/240\n50/50 - 0s - loss: 0.4833 - auc: 0.8032 - val_loss: 0.5055 - val_auc: 0.7500\nEpoch 74/240\n50/50 - 0s - loss: 0.4827 - auc: 0.8060 - val_loss: 0.5055 - val_auc: 0.7505\nEpoch 75/240\n50/50 - 0s - loss: 0.4669 - auc: 0.8216 - val_loss: 0.5065 - val_auc: 0.7495\nEpoch 76/240\n50/50 - 0s - loss: 0.4817 - auc: 0.8078 - val_loss: 0.5064 - val_auc: 0.7507\nEpoch 77/240\n50/50 - 0s - loss: 0.4709 - auc: 0.8150 - val_loss: 0.5064 - val_auc: 0.7507\n训练集AUC 0.8450362660691119\n测试集AUC 0.7504960317460316\n"}],"execution_count":1},{"cell_type":"markdown","metadata":{"id":"4041DF9A49894A9093D81F9AEEB5EE32","notebookId":"6515d257d40e0c1a5867aec8","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"## 2. 卷积神经网络CNN"},{"cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"16BEDEF83DF24B65ABB0E52615CECDCB","scrolled":false,"notebookId":"6515d257d40e0c1a5867aec8"},"source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras import layers, models, callbacks\n\nfrom utils import data_utils\n\n# 加载数据集\ntrain_x, test_x, train_y, test_y = data_utils.get_x_y_split(transform_method='standard')\n\n# 数据预处理\ntrain_x = train_x.to_numpy().reshape((train_x.shape[0], train_x.shape[1], 1))\ntest_x = test_x.to_numpy().reshape((test_x.shape[0], test_x.shape[1], 1))\ntrain_y = train_y.values.reshape((train_y.shape[0], 1))\ntest_y = test_y.values.reshape((test_y.shape[0], 1))\n\n# 设置随机数种子，保证每次运行结果一致\ntf.random.set_seed(1)\ncallback = callbacks.EarlyStopping(monitor='val_loss', patience=30, mode='min')\n\n# 构建CNN模型结构\nmodel = models.Sequential()\nmodel.add(layers.Conv1D(filters=16, kernel_size=4, activation='relu', input_shape=(train_x.shape[1], 1)))\nmodel.add(layers.Conv1D(filters=8, kernel_size=1, activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.3, seed=1))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n# 显示模型的结构\nmodel.summary()\n\n# 设置模型训练参数\nmodel.compile(optimizer='SGD',\n              metrics=[tf.metrics.AUC()],\n              loss='binary_crossentropy')\n# 模型训练\nmodel.fit(train_x, train_y, validation_data=(test_x, test_y), batch_size=16, epochs=240, callbacks=[callback], verbose=2)\n\n# 测试集效果评估\nauc_score = roc_auc_score(train_y, model.predict(train_x))\nprint(\"训练集AUC\", auc_score)\nauc_score = roc_auc_score(test_y, model.predict(test_x))\nprint(\"测试集AUC\", auc_score)\n","outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d (Conv1D)              (None, 17, 16)            80        \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 17, 8)             136       \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 136)               0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 136)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 16)                2192      \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 2,425\nTrainable params: 2,425\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/240\n50/50 - 1s - loss: 0.6618 - auc_1: 0.4975 - val_loss: 0.6398 - val_auc_1: 0.4996\nEpoch 2/240\n50/50 - 0s - loss: 0.6369 - auc_1: 0.4916 - val_loss: 0.6171 - val_auc_1: 0.5051\nEpoch 3/240\n50/50 - 0s - loss: 0.6209 - auc_1: 0.5240 - val_loss: 0.6042 - val_auc_1: 0.5178\nEpoch 4/240\n50/50 - 0s - loss: 0.6259 - auc_1: 0.4691 - val_loss: 0.5986 - val_auc_1: 0.5284\nEpoch 5/240\n50/50 - 0s - loss: 0.6200 - auc_1: 0.5029 - val_loss: 0.5944 - val_auc_1: 0.5364\nEpoch 6/240\n50/50 - 0s - loss: 0.6135 - auc_1: 0.5376 - val_loss: 0.5909 - val_auc_1: 0.5498\nEpoch 7/240\n50/50 - 0s - loss: 0.6057 - auc_1: 0.5805 - val_loss: 0.5883 - val_auc_1: 0.5583\nEpoch 8/240\n50/50 - 0s - loss: 0.6105 - auc_1: 0.5462 - val_loss: 0.5869 - val_auc_1: 0.5775\nEpoch 9/240\n50/50 - 0s - loss: 0.6023 - auc_1: 0.6050 - val_loss: 0.5844 - val_auc_1: 0.5851\nEpoch 10/240\n50/50 - 0s - loss: 0.6057 - auc_1: 0.5783 - val_loss: 0.5828 - val_auc_1: 0.5918\nEpoch 11/240\n50/50 - 0s - loss: 0.6002 - auc_1: 0.6035 - val_loss: 0.5815 - val_auc_1: 0.6016\nEpoch 12/240\n50/50 - 0s - loss: 0.5975 - auc_1: 0.6170 - val_loss: 0.5799 - val_auc_1: 0.6112\nEpoch 13/240\n50/50 - 0s - loss: 0.5987 - auc_1: 0.6008 - val_loss: 0.5777 - val_auc_1: 0.6186\nEpoch 14/240\n50/50 - 0s - loss: 0.5954 - auc_1: 0.6254 - val_loss: 0.5759 - val_auc_1: 0.6265\nEpoch 15/240\n50/50 - 0s - loss: 0.5916 - auc_1: 0.6327 - val_loss: 0.5747 - val_auc_1: 0.6314\nEpoch 16/240\n50/50 - 0s - loss: 0.5863 - auc_1: 0.6660 - val_loss: 0.5724 - val_auc_1: 0.6363\nEpoch 17/240\n50/50 - 0s - loss: 0.5842 - auc_1: 0.6551 - val_loss: 0.5713 - val_auc_1: 0.6440\nEpoch 18/240\n50/50 - 0s - loss: 0.5849 - auc_1: 0.6558 - val_loss: 0.5695 - val_auc_1: 0.6466\nEpoch 19/240\n50/50 - 0s - loss: 0.5823 - auc_1: 0.6727 - val_loss: 0.5685 - val_auc_1: 0.6524\nEpoch 20/240\n50/50 - 0s - loss: 0.5864 - auc_1: 0.6519 - val_loss: 0.5673 - val_auc_1: 0.6554\nEpoch 21/240\n50/50 - 0s - loss: 0.5782 - auc_1: 0.6804 - val_loss: 0.5659 - val_auc_1: 0.6614\nEpoch 22/240\n50/50 - 0s - loss: 0.5826 - auc_1: 0.6670 - val_loss: 0.5651 - val_auc_1: 0.6633\nEpoch 23/240\n50/50 - 0s - loss: 0.5747 - auc_1: 0.6920 - val_loss: 0.5633 - val_auc_1: 0.6684\nEpoch 24/240\n50/50 - 0s - loss: 0.5710 - auc_1: 0.6920 - val_loss: 0.5612 - val_auc_1: 0.6722\nEpoch 25/240\n50/50 - 0s - loss: 0.5730 - auc_1: 0.6846 - val_loss: 0.5600 - val_auc_1: 0.6766\nEpoch 26/240\n50/50 - 0s - loss: 0.5729 - auc_1: 0.6869 - val_loss: 0.5590 - val_auc_1: 0.6775\nEpoch 27/240\n50/50 - 0s - loss: 0.5713 - auc_1: 0.6860 - val_loss: 0.5579 - val_auc_1: 0.6827\nEpoch 28/240\n50/50 - 0s - loss: 0.5715 - auc_1: 0.6823 - val_loss: 0.5565 - val_auc_1: 0.6838\nEpoch 29/240\n50/50 - 0s - loss: 0.5695 - auc_1: 0.6968 - val_loss: 0.5556 - val_auc_1: 0.6853\nEpoch 30/240\n50/50 - 0s - loss: 0.5649 - auc_1: 0.7006 - val_loss: 0.5543 - val_auc_1: 0.6881\nEpoch 31/240\n50/50 - 0s - loss: 0.5644 - auc_1: 0.7066 - val_loss: 0.5530 - val_auc_1: 0.6911\nEpoch 32/240\n50/50 - 0s - loss: 0.5699 - auc_1: 0.6872 - val_loss: 0.5525 - val_auc_1: 0.6905\nEpoch 33/240\n50/50 - 0s - loss: 0.5574 - auc_1: 0.7139 - val_loss: 0.5515 - val_auc_1: 0.6923\nEpoch 34/240\n50/50 - 0s - loss: 0.5687 - auc_1: 0.6813 - val_loss: 0.5506 - val_auc_1: 0.6943\nEpoch 35/240\n50/50 - 0s - loss: 0.5611 - auc_1: 0.7102 - val_loss: 0.5491 - val_auc_1: 0.6960\nEpoch 36/240\n50/50 - 0s - loss: 0.5629 - auc_1: 0.7020 - val_loss: 0.5477 - val_auc_1: 0.6986\nEpoch 37/240\n50/50 - 0s - loss: 0.5553 - auc_1: 0.7179 - val_loss: 0.5468 - val_auc_1: 0.7001\nEpoch 38/240\n50/50 - 0s - loss: 0.5586 - auc_1: 0.7052 - val_loss: 0.5463 - val_auc_1: 0.7013\nEpoch 39/240\n50/50 - 0s - loss: 0.5532 - auc_1: 0.7189 - val_loss: 0.5452 - val_auc_1: 0.7012\nEpoch 40/240\n50/50 - 0s - loss: 0.5540 - auc_1: 0.7146 - val_loss: 0.5444 - val_auc_1: 0.7039\nEpoch 41/240\n50/50 - 0s - loss: 0.5586 - auc_1: 0.7077 - val_loss: 0.5433 - val_auc_1: 0.7051\nEpoch 42/240\n50/50 - 0s - loss: 0.5520 - auc_1: 0.7177 - val_loss: 0.5424 - val_auc_1: 0.7047\nEpoch 43/240\n50/50 - 0s - loss: 0.5530 - auc_1: 0.7197 - val_loss: 0.5418 - val_auc_1: 0.7052\nEpoch 44/240\n50/50 - 0s - loss: 0.5480 - auc_1: 0.7258 - val_loss: 0.5407 - val_auc_1: 0.7073\nEpoch 45/240\n50/50 - 0s - loss: 0.5560 - auc_1: 0.7066 - val_loss: 0.5397 - val_auc_1: 0.7104\nEpoch 46/240\n50/50 - 0s - loss: 0.5458 - auc_1: 0.7320 - val_loss: 0.5390 - val_auc_1: 0.7111\nEpoch 47/240\n50/50 - 0s - loss: 0.5419 - auc_1: 0.7365 - val_loss: 0.5383 - val_auc_1: 0.7107\nEpoch 48/240\n50/50 - 0s - loss: 0.5393 - auc_1: 0.7454 - val_loss: 0.5371 - val_auc_1: 0.7118\nEpoch 49/240\n50/50 - 0s - loss: 0.5349 - auc_1: 0.7441 - val_loss: 0.5363 - val_auc_1: 0.7110\nEpoch 50/240\n50/50 - 0s - loss: 0.5477 - auc_1: 0.7265 - val_loss: 0.5357 - val_auc_1: 0.7136\nEpoch 51/240\n50/50 - 0s - loss: 0.5342 - auc_1: 0.7448 - val_loss: 0.5351 - val_auc_1: 0.7122\nEpoch 52/240\n50/50 - 0s - loss: 0.5347 - auc_1: 0.7448 - val_loss: 0.5344 - val_auc_1: 0.7131\nEpoch 53/240\n50/50 - 0s - loss: 0.5424 - auc_1: 0.7338 - val_loss: 0.5343 - val_auc_1: 0.7140\nEpoch 54/240\n50/50 - 0s - loss: 0.5262 - auc_1: 0.7607 - val_loss: 0.5336 - val_auc_1: 0.7132\nEpoch 55/240\n50/50 - 0s - loss: 0.5292 - auc_1: 0.7508 - val_loss: 0.5328 - val_auc_1: 0.7143\nEpoch 56/240\n50/50 - 0s - loss: 0.5219 - auc_1: 0.7673 - val_loss: 0.5312 - val_auc_1: 0.7168\nEpoch 57/240\n50/50 - 0s - loss: 0.5426 - auc_1: 0.7309 - val_loss: 0.5305 - val_auc_1: 0.7190\nEpoch 58/240\n50/50 - 0s - loss: 0.5272 - auc_1: 0.7638 - val_loss: 0.5294 - val_auc_1: 0.7202\nEpoch 59/240\n50/50 - 0s - loss: 0.5233 - auc_1: 0.7618 - val_loss: 0.5289 - val_auc_1: 0.7207\nEpoch 60/240\n50/50 - 0s - loss: 0.5382 - auc_1: 0.7349 - val_loss: 0.5286 - val_auc_1: 0.7217\nEpoch 61/240\n50/50 - 0s - loss: 0.5183 - auc_1: 0.7692 - val_loss: 0.5268 - val_auc_1: 0.7245\nEpoch 62/240\n50/50 - 0s - loss: 0.5239 - auc_1: 0.7587 - val_loss: 0.5269 - val_auc_1: 0.7243\nEpoch 63/240\n50/50 - 0s - loss: 0.5278 - auc_1: 0.7493 - val_loss: 0.5263 - val_auc_1: 0.7258\nEpoch 64/240\n50/50 - 0s - loss: 0.5159 - auc_1: 0.7676 - val_loss: 0.5258 - val_auc_1: 0.7251\nEpoch 65/240\n50/50 - 0s - loss: 0.5264 - auc_1: 0.7556 - val_loss: 0.5250 - val_auc_1: 0.7276\nEpoch 66/240\n50/50 - 0s - loss: 0.5242 - auc_1: 0.7574 - val_loss: 0.5242 - val_auc_1: 0.7277\nEpoch 67/240\n50/50 - 0s - loss: 0.5264 - auc_1: 0.7570 - val_loss: 0.5232 - val_auc_1: 0.7287\nEpoch 68/240\n50/50 - 0s - loss: 0.5176 - auc_1: 0.7691 - val_loss: 0.5225 - val_auc_1: 0.7292\nEpoch 69/240\n50/50 - 0s - loss: 0.5086 - auc_1: 0.7772 - val_loss: 0.5223 - val_auc_1: 0.7299\nEpoch 70/240\n50/50 - 0s - loss: 0.5224 - auc_1: 0.7582 - val_loss: 0.5219 - val_auc_1: 0.7301\nEpoch 71/240\n50/50 - 0s - loss: 0.5148 - auc_1: 0.7679 - val_loss: 0.5213 - val_auc_1: 0.7322\nEpoch 72/240\n50/50 - 0s - loss: 0.5100 - auc_1: 0.7745 - val_loss: 0.5201 - val_auc_1: 0.7323\nEpoch 73/240\n50/50 - 0s - loss: 0.5230 - auc_1: 0.7572 - val_loss: 0.5207 - val_auc_1: 0.7316\nEpoch 74/240\n50/50 - 0s - loss: 0.5177 - auc_1: 0.7654 - val_loss: 0.5196 - val_auc_1: 0.7333\nEpoch 75/240\n50/50 - 0s - loss: 0.5070 - auc_1: 0.7821 - val_loss: 0.5188 - val_auc_1: 0.7356\nEpoch 76/240\n50/50 - 0s - loss: 0.5125 - auc_1: 0.7759 - val_loss: 0.5179 - val_auc_1: 0.7372\nEpoch 77/240\n50/50 - 0s - loss: 0.5058 - auc_1: 0.7844 - val_loss: 0.5172 - val_auc_1: 0.7380\nEpoch 78/240\n50/50 - 0s - loss: 0.4972 - auc_1: 0.7869 - val_loss: 0.5168 - val_auc_1: 0.7365\nEpoch 79/240\n50/50 - 0s - loss: 0.5007 - auc_1: 0.7865 - val_loss: 0.5165 - val_auc_1: 0.7367\nEpoch 80/240\n50/50 - 0s - loss: 0.5075 - auc_1: 0.7815 - val_loss: 0.5167 - val_auc_1: 0.7389\nEpoch 81/240\n50/50 - 0s - loss: 0.4959 - auc_1: 0.7872 - val_loss: 0.5163 - val_auc_1: 0.7388\nEpoch 82/240\n50/50 - 0s - loss: 0.5105 - auc_1: 0.7769 - val_loss: 0.5160 - val_auc_1: 0.7393\nEpoch 83/240\n50/50 - 0s - loss: 0.5168 - auc_1: 0.7643 - val_loss: 0.5155 - val_auc_1: 0.7396\nEpoch 84/240\n50/50 - 0s - loss: 0.5052 - auc_1: 0.7795 - val_loss: 0.5161 - val_auc_1: 0.7391\nEpoch 85/240\n50/50 - 0s - loss: 0.5019 - auc_1: 0.7876 - val_loss: 0.5164 - val_auc_1: 0.7388\nEpoch 86/240\n50/50 - 0s - loss: 0.5001 - auc_1: 0.7876 - val_loss: 0.5166 - val_auc_1: 0.7390\nEpoch 87/240\n50/50 - 0s - loss: 0.4962 - auc_1: 0.7929 - val_loss: 0.5165 - val_auc_1: 0.7395\nEpoch 88/240\n50/50 - 0s - loss: 0.5000 - auc_1: 0.7897 - val_loss: 0.5160 - val_auc_1: 0.7400\nEpoch 89/240\n50/50 - 0s - loss: 0.5080 - auc_1: 0.7758 - val_loss: 0.5171 - val_auc_1: 0.7379\nEpoch 90/240\n50/50 - 0s - loss: 0.4962 - auc_1: 0.7917 - val_loss: 0.5162 - val_auc_1: 0.7409\nEpoch 91/240\n50/50 - 0s - loss: 0.4995 - auc_1: 0.7885 - val_loss: 0.5166 - val_auc_1: 0.7403\nEpoch 92/240\n50/50 - 0s - loss: 0.5007 - auc_1: 0.7874 - val_loss: 0.5161 - val_auc_1: 0.7399\nEpoch 93/240\n50/50 - 0s - loss: 0.5035 - auc_1: 0.7844 - val_loss: 0.5162 - val_auc_1: 0.7380\nEpoch 94/240\n50/50 - 0s - loss: 0.5022 - auc_1: 0.7849 - val_loss: 0.5159 - val_auc_1: 0.7405\nEpoch 95/240\n50/50 - 0s - loss: 0.5083 - auc_1: 0.7769 - val_loss: 0.5147 - val_auc_1: 0.7416\nEpoch 96/240\n50/50 - 0s - loss: 0.5034 - auc_1: 0.7829 - val_loss: 0.5161 - val_auc_1: 0.7411\nEpoch 97/240\n50/50 - 0s - loss: 0.4902 - auc_1: 0.7972 - val_loss: 0.5159 - val_auc_1: 0.7391\nEpoch 98/240\n50/50 - 0s - loss: 0.4924 - auc_1: 0.7964 - val_loss: 0.5152 - val_auc_1: 0.7406\nEpoch 99/240\n50/50 - 0s - loss: 0.4860 - auc_1: 0.8019 - val_loss: 0.5162 - val_auc_1: 0.7400\nEpoch 100/240\n50/50 - 0s - loss: 0.4792 - auc_1: 0.8090 - val_loss: 0.5162 - val_auc_1: 0.7404\nEpoch 101/240\n50/50 - 0s - loss: 0.4906 - auc_1: 0.7973 - val_loss: 0.5163 - val_auc_1: 0.7401\nEpoch 102/240\n50/50 - 0s - loss: 0.5049 - auc_1: 0.7835 - val_loss: 0.5163 - val_auc_1: 0.7405\nEpoch 103/240\n50/50 - 0s - loss: 0.4944 - auc_1: 0.7892 - val_loss: 0.5161 - val_auc_1: 0.7405\nEpoch 104/240\n50/50 - 0s - loss: 0.4995 - auc_1: 0.7879 - val_loss: 0.5168 - val_auc_1: 0.7421\nEpoch 105/240\n50/50 - 0s - loss: 0.4859 - auc_1: 0.8024 - val_loss: 0.5159 - val_auc_1: 0.7424\nEpoch 106/240\n50/50 - 0s - loss: 0.5040 - auc_1: 0.7814 - val_loss: 0.5148 - val_auc_1: 0.7431\nEpoch 107/240\n50/50 - 0s - loss: 0.4927 - auc_1: 0.7948 - val_loss: 0.5161 - val_auc_1: 0.7426\nEpoch 108/240\n50/50 - 0s - loss: 0.4948 - auc_1: 0.7948 - val_loss: 0.5154 - val_auc_1: 0.7426\nEpoch 109/240\n50/50 - 0s - loss: 0.4955 - auc_1: 0.7924 - val_loss: 0.5150 - val_auc_1: 0.7435\nEpoch 110/240\n50/50 - 0s - loss: 0.5008 - auc_1: 0.7846 - val_loss: 0.5145 - val_auc_1: 0.7416\nEpoch 111/240\n50/50 - 0s - loss: 0.4834 - auc_1: 0.8069 - val_loss: 0.5149 - val_auc_1: 0.7410\nEpoch 112/240\n50/50 - 0s - loss: 0.4998 - auc_1: 0.7874 - val_loss: 0.5139 - val_auc_1: 0.7422\nEpoch 113/240\n50/50 - 0s - loss: 0.4920 - auc_1: 0.8019 - val_loss: 0.5144 - val_auc_1: 0.7449\nEpoch 114/240\n50/50 - 0s - loss: 0.4811 - auc_1: 0.8052 - val_loss: 0.5135 - val_auc_1: 0.7444\nEpoch 115/240\n50/50 - 0s - loss: 0.4821 - auc_1: 0.8067 - val_loss: 0.5147 - val_auc_1: 0.7444\nEpoch 116/240\n50/50 - 0s - loss: 0.4809 - auc_1: 0.8076 - val_loss: 0.5133 - val_auc_1: 0.7449\nEpoch 117/240\n50/50 - 0s - loss: 0.5031 - auc_1: 0.7859 - val_loss: 0.5133 - val_auc_1: 0.7448\nEpoch 118/240\n50/50 - 0s - loss: 0.4832 - auc_1: 0.8063 - val_loss: 0.5148 - val_auc_1: 0.7431\nEpoch 119/240\n50/50 - 0s - loss: 0.4905 - auc_1: 0.7948 - val_loss: 0.5145 - val_auc_1: 0.7426\nEpoch 120/240\n50/50 - 0s - loss: 0.4850 - auc_1: 0.8081 - val_loss: 0.5163 - val_auc_1: 0.7432\nEpoch 121/240\n50/50 - 0s - loss: 0.4850 - auc_1: 0.8009 - val_loss: 0.5155 - val_auc_1: 0.7418\nEpoch 122/240\n50/50 - 0s - loss: 0.4866 - auc_1: 0.8047 - val_loss: 0.5158 - val_auc_1: 0.7444\nEpoch 123/240\n50/50 - 0s - loss: 0.4780 - auc_1: 0.8129 - val_loss: 0.5143 - val_auc_1: 0.7432\nEpoch 124/240\n50/50 - 0s - loss: 0.4653 - auc_1: 0.8258 - val_loss: 0.5159 - val_auc_1: 0.7431\nEpoch 125/240\n50/50 - 0s - loss: 0.4930 - auc_1: 0.7928 - val_loss: 0.5154 - val_auc_1: 0.7419\nEpoch 126/240\n50/50 - 0s - loss: 0.4884 - auc_1: 0.7974 - val_loss: 0.5151 - val_auc_1: 0.7416\nEpoch 127/240\n50/50 - 0s - loss: 0.4934 - auc_1: 0.7953 - val_loss: 0.5146 - val_auc_1: 0.7426\nEpoch 128/240\n50/50 - 0s - loss: 0.4823 - auc_1: 0.8057 - val_loss: 0.5147 - val_auc_1: 0.7435\nEpoch 129/240\n50/50 - 0s - loss: 0.4760 - auc_1: 0.8101 - val_loss: 0.5137 - val_auc_1: 0.7450\nEpoch 130/240\n50/50 - 0s - loss: 0.4785 - auc_1: 0.8107 - val_loss: 0.5150 - val_auc_1: 0.7463\nEpoch 131/240\n50/50 - 0s - loss: 0.4872 - auc_1: 0.8001 - val_loss: 0.5147 - val_auc_1: 0.7430\nEpoch 132/240\n50/50 - 0s - loss: 0.4749 - auc_1: 0.8138 - val_loss: 0.5149 - val_auc_1: 0.7428\nEpoch 133/240\n50/50 - 0s - loss: 0.4918 - auc_1: 0.7939 - val_loss: 0.5147 - val_auc_1: 0.7463\nEpoch 134/240\n50/50 - 0s - loss: 0.4747 - auc_1: 0.8155 - val_loss: 0.5144 - val_auc_1: 0.7462\nEpoch 135/240\n50/50 - 0s - loss: 0.4875 - auc_1: 0.8016 - val_loss: 0.5122 - val_auc_1: 0.7477\nEpoch 136/240\n50/50 - 0s - loss: 0.4685 - auc_1: 0.8195 - val_loss: 0.5138 - val_auc_1: 0.7465\nEpoch 137/240\n50/50 - 0s - loss: 0.4800 - auc_1: 0.8100 - val_loss: 0.5127 - val_auc_1: 0.7462\nEpoch 138/240\n50/50 - 0s - loss: 0.4714 - auc_1: 0.8168 - val_loss: 0.5131 - val_auc_1: 0.7486\nEpoch 139/240\n50/50 - 0s - loss: 0.4681 - auc_1: 0.8188 - val_loss: 0.5119 - val_auc_1: 0.7489\nEpoch 140/240\n50/50 - 0s - loss: 0.4811 - auc_1: 0.8055 - val_loss: 0.5127 - val_auc_1: 0.7470\nEpoch 141/240\n50/50 - 0s - loss: 0.4709 - auc_1: 0.8168 - val_loss: 0.5128 - val_auc_1: 0.7476\nEpoch 142/240\n50/50 - 0s - loss: 0.4943 - auc_1: 0.7950 - val_loss: 0.5128 - val_auc_1: 0.7494\nEpoch 143/240\n50/50 - 0s - loss: 0.4769 - auc_1: 0.8116 - val_loss: 0.5131 - val_auc_1: 0.7478\nEpoch 144/240\n50/50 - 0s - loss: 0.4847 - auc_1: 0.8018 - val_loss: 0.5134 - val_auc_1: 0.7463\nEpoch 145/240\n50/50 - 0s - loss: 0.4789 - auc_1: 0.8106 - val_loss: 0.5128 - val_auc_1: 0.7502\nEpoch 146/240\n50/50 - 0s - loss: 0.4697 - auc_1: 0.8178 - val_loss: 0.5134 - val_auc_1: 0.7499\nEpoch 147/240\n50/50 - 0s - loss: 0.4795 - auc_1: 0.8065 - val_loss: 0.5128 - val_auc_1: 0.7493\nEpoch 148/240\n50/50 - 0s - loss: 0.4745 - auc_1: 0.8133 - val_loss: 0.5142 - val_auc_1: 0.7461\nEpoch 149/240\n50/50 - 0s - loss: 0.4709 - auc_1: 0.8176 - val_loss: 0.5127 - val_auc_1: 0.7476\nEpoch 150/240\n50/50 - 0s - loss: 0.4819 - auc_1: 0.8077 - val_loss: 0.5132 - val_auc_1: 0.7466\nEpoch 151/240\n50/50 - 0s - loss: 0.4667 - auc_1: 0.8223 - val_loss: 0.5134 - val_auc_1: 0.7467\nEpoch 152/240\n50/50 - 0s - loss: 0.4703 - auc_1: 0.8168 - val_loss: 0.5142 - val_auc_1: 0.7471\nEpoch 153/240\n50/50 - 0s - loss: 0.4721 - auc_1: 0.8181 - val_loss: 0.5136 - val_auc_1: 0.7485\nEpoch 154/240\n50/50 - 0s - loss: 0.4761 - auc_1: 0.8121 - val_loss: 0.5147 - val_auc_1: 0.7473\nEpoch 155/240\n50/50 - 0s - loss: 0.4805 - auc_1: 0.8084 - val_loss: 0.5147 - val_auc_1: 0.7480\nEpoch 156/240\n50/50 - 0s - loss: 0.4921 - auc_1: 0.7946 - val_loss: 0.5142 - val_auc_1: 0.7450\nEpoch 157/240\n50/50 - 0s - loss: 0.4868 - auc_1: 0.7995 - val_loss: 0.5147 - val_auc_1: 0.7455\nEpoch 158/240\n50/50 - 0s - loss: 0.4586 - auc_1: 0.8294 - val_loss: 0.5153 - val_auc_1: 0.7446\nEpoch 159/240\n50/50 - 0s - loss: 0.4544 - auc_1: 0.8365 - val_loss: 0.5151 - val_auc_1: 0.7488\nEpoch 160/240\n50/50 - 0s - loss: 0.4685 - auc_1: 0.8216 - val_loss: 0.5146 - val_auc_1: 0.7507\nEpoch 161/240\n50/50 - 0s - loss: 0.4705 - auc_1: 0.8159 - val_loss: 0.5135 - val_auc_1: 0.7509\nEpoch 162/240\n50/50 - 0s - loss: 0.4687 - auc_1: 0.8197 - val_loss: 0.5153 - val_auc_1: 0.7464\nEpoch 163/240\n50/50 - 0s - loss: 0.4674 - auc_1: 0.8224 - val_loss: 0.5140 - val_auc_1: 0.7468\nEpoch 164/240\n50/50 - 0s - loss: 0.4682 - auc_1: 0.8163 - val_loss: 0.5146 - val_auc_1: 0.7450\nEpoch 165/240\n50/50 - 0s - loss: 0.4668 - auc_1: 0.8248 - val_loss: 0.5143 - val_auc_1: 0.7470\nEpoch 166/240\n50/50 - 0s - loss: 0.4618 - auc_1: 0.8242 - val_loss: 0.5141 - val_auc_1: 0.7473\nEpoch 167/240\n50/50 - 0s - loss: 0.4807 - auc_1: 0.8040 - val_loss: 0.5144 - val_auc_1: 0.7458\nEpoch 168/240\n50/50 - 0s - loss: 0.4670 - auc_1: 0.8223 - val_loss: 0.5144 - val_auc_1: 0.7479\nEpoch 169/240\n50/50 - 0s - loss: 0.4649 - auc_1: 0.8223 - val_loss: 0.5142 - val_auc_1: 0.7476\n训练集AUC 0.8623216181153437\n测试集AUC 0.747891865079365\n"}],"execution_count":2}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}