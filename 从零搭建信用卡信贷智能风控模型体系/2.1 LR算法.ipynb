{"cells":[{"cell_type":"markdown","metadata":{"trusted":true,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"D89B0EAB542642F98900CCC4D4E49360","runtime":{"status":"default","execution_status":null,"is_visible":false},"scrolled":false,"notebookId":"6515c98fc6bc713b13742f76"},"source":"## LR（Logistic Regression）  \n\n逻辑回归是常见的分类算法，可解释强，在风控领域被广泛应用。  \n逻辑回归假设数据服从伯努利分布，其学习策略可形式化为极大似然，也等价于正则化的对数损失函数的最小化问题。  \n"},{"cell_type":"code","metadata":{"id":"810CF482643D4985AFA558B9F60AF78D","notebookId":"6515c98fc6bc713b13742f76","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"source":"import sys\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom category_encoders.woe import WOEEncoder\n\nfrom utils import data_utils","outputs":[],"execution_count":1},{"cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"4FC61B519BE24DD590C9913A15FBDA95","scrolled":false,"notebookId":"6515c98fc6bc713b13742f76"},"source":"# 导入数值型样例数据\ntrain_x, test_x, train_y, test_y = data_utils.get_x_y_split(test_rate=0.2)","outputs":[],"execution_count":2},{"cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"16BEDEF83DF24B65ABB0E52615CECDCB","scrolled":false,"notebookId":"6515c98fc6bc713b13742f76"},"source":"# woe特征处理\nencoder = WOEEncoder(cols=train_x.columns)\ntrain_x = encoder.fit_transform(train_x, train_y)\ntest_x = encoder.transform(test_x)","outputs":[],"execution_count":3},{"cell_type":"code","metadata":{"id":"DA20C754298644F89074BA60AFE6FCAD","notebookId":"6515c98fc6bc713b13742f76","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 利用梯度下降法训练逻辑回归模型\nlr = SGDClassifier(loss=\"log\",\n                   penalty=\"l2\",\n                   learning_rate='optimal',\n                   max_iter=100,\n                   tol=0.001,\n                   epsilon=0.1,\n                   random_state=1)\nclf = make_pipeline(StandardScaler(), lr)\nclf.fit(train_x, train_y)\nauc_score = roc_auc_score(test_y, clf.predict_proba(test_x)[:, 1])\nprint(\"梯度下降法训练逻辑回归模型 AUC: \", auc_score)","outputs":[{"output_type":"stream","name":"stdout","text":"梯度下降法训练逻辑回归模型 AUC:  0.7276785714285714\n"}],"execution_count":4},{"cell_type":"code","metadata":{"id":"8CCF7C3EB12A4EFB9168585220900C0B","notebookId":"6515c98fc6bc713b13742f76","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 利用牛顿法训练逻辑回归模型\nlr = LogisticRegression(penalty=\"l2\",\n                        solver='lbfgs',\n                        max_iter=100,\n                        tol=0.001,\n                        random_state=1)\nclf = make_pipeline(StandardScaler(), lr)\nclf.fit(train_x, train_y)\nauc_score = roc_auc_score(test_y, clf.predict_proba(test_x)[:, 1])\nprint(\"牛顿法训练逻辑回归模型 AUC: \", auc_score)","outputs":[{"output_type":"stream","name":"stdout","text":"牛顿法训练逻辑回归模型 AUC:  0.7353670634920635\n"}],"execution_count":5}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}